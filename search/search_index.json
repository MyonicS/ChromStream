{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"<p>A Python package for processing on-line gas chromatography data. ChromStream provides tools to parse, analyze, and visualize chromatographic data from various GC systems, and combine it with data from logfiles such as temperature and pressure.</p>"},{"location":"index.html#features","title":"Features","text":"<ul> <li>Parse chromatographic data from multiple formats (Chromeleon, FID, etc.)</li> <li>Access to data at experiment, channel and chromatogram level</li> <li>Quick plotting of chromatograms</li> <li>Small selection of baseline corrections, possibility to use custom ones</li> <li>Integration using a dict of peaks</li> <li>Addition of logfiles</li> </ul>"},{"location":"index.html#installation","title":"Installation","text":"<p>Chromstream is presently not availible on PyPi. You can however install it straight from the repository:</p>"},{"location":"index.html#install-from-git-repository","title":"Install from Git Repository","text":"<pre><code>pip install git+https://github.com/MyonicS/ChromStream\n</code></pre>"},{"location":"index.html#install-using-uv","title":"Install using uv","text":"<p>If you're using uv for fast Python package management:</p> <pre><code>uv add git+https://github.com/MyonicS/ChromStream\n</code></pre>"},{"location":"index.html#quick-start","title":"Quick Start","text":"<p>Check the Quickstart Notebook to see a full demonstration of the most important features of the package.  Here's a simple example of how to set up an experiment, add chromatograms and plot them:</p> <pre><code>import chromstream as cs\n\nexp = cs.Experiment(name='hello there')\nexp.add_chromatogram('path-to-your-chromatogram') #loop over files to add multiple\nexp.plot_chromatograms()\n</code></pre> <p>To access specific channels: <pre><code>exp.channels['channel-name'].plot()\n</code></pre></p> <p>For specific chromatograms:</p> <pre><code>exp.channels['channel-name'].chromatograms[0].plot()\n</code></pre>"},{"location":"index.html#supported-file-formats","title":"Supported File Formats","text":"<p>ChromStream currently supports parsing data from:</p> <ul> <li>Chromeleon software exports (<code>.txt</code>)</li> <li>(software names) (ascii files)</li> <li>simple log files (e.g. exported from labview)</li> </ul>"},{"location":"index.html#documentation","title":"Documentation","text":"<ul> <li>You can find the full documentation of the package here.</li> </ul>"},{"location":"index.html#example-notebooks","title":"Example Notebooks","text":"<p>Check out the <code>example_notebooks/</code> directory for comprehensive examples:</p> <ul> <li><code>example_calibration.ipynb</code> - GC calibration procedures</li> </ul>"},{"location":"index.html#roadmap","title":"Roadmap","text":"<ul> <li>Support for more files formats</li> <li>Addition of more data sources such as spectroscopy</li> <li>JSON saving and parsings</li> <li>tests</li> </ul>"},{"location":"index.html#contributing","title":"Contributing","text":"<p>This package is in active development. Any help is appreciated. You can submit feature requests or bug reports as issues on the repository. If you have a specific file format which presently is nto supported please provide an example file. PRs are more than welcome.</p>"},{"location":"index.html#authors","title":"Authors","text":"<p>Sebastian Rejman - Utrecht University</p>"},{"location":"gen_ref_pages.html","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"\nGenerate the code reference pages and navigation.\n\nYou never have to run this manually!\n\"\"\"\n</pre> \"\"\" Generate the code reference pages and navigation.  You never have to run this manually! \"\"\" In\u00a0[\u00a0]: Copied! <pre>from __future__ import annotations\n</pre> from __future__ import annotations In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n</pre> nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>for path in sorted(Path(\"src\").rglob(\"*.py\")):\n    module_path = path.relative_to(\"src\").with_suffix(\"\")\n    doc_path = path.relative_to(\"src\").with_suffix(\".md\")\n    full_doc_path = Path(\"reference\", doc_path)\n\n    parts = tuple(module_path.parts)\n\n    if parts[-1] in (\"__init__\", \"__main__\"):\n        continue\n\n    nav[parts] = doc_path.as_posix()\n\n    with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n        ident = \".\".join(parts)\n        fd.write(f\"::: {ident}\")\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path)\n</pre> for path in sorted(Path(\"src\").rglob(\"*.py\")):     module_path = path.relative_to(\"src\").with_suffix(\"\")     doc_path = path.relative_to(\"src\").with_suffix(\".md\")     full_doc_path = Path(\"reference\", doc_path)      parts = tuple(module_path.parts)      if parts[-1] in (\"__init__\", \"__main__\"):         continue      nav[parts] = doc_path.as_posix()      with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:         ident = \".\".join(parts)         fd.write(f\"::: {ident}\")      mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path) In\u00a0[\u00a0]: Copied! <pre>with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"credits/citing.html","title":"Citing ChromStream","text":"<p>If you use ChromStream in your research, please consider citing it to help support the project and make it easier for others to find.</p>"},{"location":"credits/citing.html#software-citation","title":"Software Citation","text":"<p>For now, please cite ChromStream as:</p> <pre><code>ChromStream: A Python package for processing on-line gas chromatography data.\nGitHub repository: https://github.com/MyonicS/ChromStream\n</code></pre>"},{"location":"credits/citing.html#bibtex-format","title":"BibTeX Format","text":"<pre><code>@software{chromstream,\n  title = {ChromStream: A Python package for processing on-line gas chromatography data},\n  author = {Rejman, Sebastian},\n  url = {https://github.com/MyonicS/ChromStream},\n  year = {2025}\n}\n</code></pre>"},{"location":"credits/contributors.html","title":"Contributors","text":""},{"location":"credits/contributors.html#authors","title":"Authors","text":"<ul> <li>Sebastian Rejman, Utrecht University</li> </ul>"},{"location":"credits/contributors.html#how-to-contribute","title":"How to Contribute","text":"<p>Interested in contributing? Check out our Contributing Guide to get started.</p>"},{"location":"credits/contributors.html#acknowledgments","title":"Acknowledgments","text":"<p>Members of the Inorganic Chemistry and Catalysis group are thanked for providing data files and suggestions.</p>"},{"location":"credits/papers.html","title":"Papers Using ChromStream","text":"<p>This page lists scientific publications that have used ChromStream for data analysis.</p>"},{"location":"credits/papers.html#published-papers","title":"Published Papers","text":"<p>No papers have been submitted yet. Be the first to publish using ChromStream!</p>"},{"location":"development/changelog.html","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"development/changelog.html#001","title":"[0.0.1]","text":""},{"location":"development/changelog.html#added","title":"Added","text":"<ul> <li>The initial release!</li> </ul>"},{"location":"development/contributing.html","title":"Contributing to ChromStream","text":"<p>Thank you for your interest in contributing to ChromStream! This package is in active development and we welcome contributions from the community.</p>"},{"location":"development/contributing.html#ways-to-contribute","title":"Ways to Contribute","text":""},{"location":"development/contributing.html#bug-reports","title":"\ud83d\udc1b Bug Reports","text":"<p>If you find a bug, please submit an issue on our GitHub repository with: - A clear description of the issue - Steps to reproduce the problem - Your environment details (Python version, OS, etc.) - Sample data files if relevant</p>"},{"location":"development/contributing.html#feature-requests","title":"\ud83d\udca1 Feature Requests","text":"<p>Have an idea for a new feature? Great! Please submit a feature request as an issue with: - A detailed description of the proposed feature - Use cases and examples</p>"},{"location":"development/contributing.html#file-format-support","title":"\ud83d\udcc1 File Format Support","text":"<p>If you have a specific file format that ChromStream doesn't currently support: - Please provide an example file - Include documentation about the format if available - Describe the software that generates these files</p>"},{"location":"development/contributing.html#code-contributions","title":"\ud83d\udd27 Code Contributions","text":"<p>We welcome pull requests! Here's how to get started:</p> <ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally:    <pre><code>git clone https://github.com/your-username/ChromStream\ncd ChromStream\n</code></pre></li> <li>Set up the development environment:    <pre><code>pip install -e .\n</code></pre></li> <li>Create a branch for your changes:    <pre><code>git checkout -b feature/your-feature-name\n</code></pre></li> <li>Make your changes and add tests if applicable</li> <li>Commit your changes with a clear commit message</li> <li>Push to your fork and submit a pull request</li> </ol>"},{"location":"development/contributing.html#development-guidelines","title":"Development Guidelines","text":""},{"location":"development/contributing.html#code-style","title":"Code Style","text":"<ul> <li>Use meaningful variable and function names</li> <li>Add docstrings to functions and classes</li> </ul>"},{"location":"development/contributing.html#testing","title":"Testing","text":"<ul> <li>(i need to add tests myself first)</li> </ul>"},{"location":"development/contributing.html#documentation","title":"Documentation","text":"<ul> <li>Update documentation for new features</li> <li>Add notebook examples for significant features</li> </ul>"},{"location":"development/contributing.html#development-roadmap","title":"Development Roadmap","text":"<p>Current priorities include: - Support for more file formats - Addition of spectroscopy data sources - JSON saving and parsing functionality - Comprehensive test suite - Performance optimizations</p>"},{"location":"development/contributing.html#getting-help","title":"Getting Help","text":"<p>If you need help with development, please do not hesitate to reach out. We appreciate all contributions, no matter how small!</p>"},{"location":"getting_started/installation.html","title":"Installation","text":"<p>ChromStream is a Python package for processing on-line gas chromatography data. Follow the instructions below to install the package.</p>"},{"location":"getting_started/installation.html#requirements","title":"Requirements","text":"<ul> <li>Python 3.8 or higher</li> <li>Git (for installing from repository)</li> </ul>"},{"location":"getting_started/installation.html#direct-installation-from-repository","title":"Direct Installation from Repository","text":"<p>ChromStream is presently not available on PyPI. You can install it directly from the GitHub repository without cloning:</p>"},{"location":"getting_started/installation.html#using-pip","title":"Using pip","text":"<pre><code>pip install git+https://github.com/MyonicS/ChromStream\n</code></pre>"},{"location":"getting_started/installation.html#using-uv","title":"Using uv","text":"<p>If you're using uv for fast Python package management:</p> <pre><code>uv add git+https://github.com/MyonicS/ChromStream\n</code></pre>"},{"location":"getting_started/installation.html#development-installation","title":"Development Installation","text":"<p>For development work or to get the latest features, you can install ChromStream in editable mode:</p>"},{"location":"getting_started/installation.html#clone-and-install-in-development-mode","title":"Clone and Install in Development Mode","text":"<pre><code># Clone the repository\ngit clone https://github.com/MyonicS/ChromStream\ncd ChromStream\n\n# Install in development mode\npip install -e .\n</code></pre>"},{"location":"getting_started/installation.html#reproduce-exact-development-environment","title":"Reproduce Exact Development Environment","text":"<p>To reproduce the exact development environment with all dependencies:</p> <pre><code># Clone the repository\ngit clone https://github.com/MyonicS/ChromStream\ncd ChromStream\n\n# Sync the exact development environment with dev and docs dependencies\nuv sync --extra dev --extra docs\n</code></pre> <p>This will install ChromStream along with all development dependencies (testing, linting, documentation, etc.) in the exact versions specified in the lock file.</p>"},{"location":"getting_started/installation.html#verify-installation","title":"Verify Installation","text":"<p>After installation, you can verify that ChromStream is installed correctly by importing it in Python:</p> <pre><code>import chromstream\nprint(\"ChromStream installed successfully!\")\n</code></pre>"},{"location":"getting_started/installation.html#next-steps","title":"Next Steps","text":"<p>Once you have ChromStream installed, check out the Quickstart Guide to learn how to use the package.</p>"},{"location":"notebooks/Quickstart.html","title":"Quickstart","text":"In\u00a0[17]: Copied! <pre>import chromstream as cs\nfrom pathlib import Path\n\ntestdata = Path(\"../..\") / \"dev_data\" / \"chroms\" /  \"pyGCMS_calibration\" / \"calibration_20250114_no1\"\nchrom_list = sorted(testdata.iterdir())\n\nchrom = cs.parse_chromatogram_txt(chrom_list[0])\n</pre> import chromstream as cs from pathlib import Path  testdata = Path(\"../..\") / \"dev_data\" / \"chroms\" /  \"pyGCMS_calibration\" / \"calibration_20250114_no1\" chrom_list = sorted(testdata.iterdir())  chrom = cs.parse_chromatogram_txt(chrom_list[0]) <p>From the chromatogram object we can access all important information as properties of the chromatogram class. The data is given as a pd.DataFrame(), the metadata is a dict. Certain properties from the metadata can be accessed directly, such as the injection time (as pd.DateTime object) or the channel:</p> In\u00a0[18]: Copied! <pre># data\nprint(chrom.data.head())\n# metadata\nprint(chrom.metadata.keys())\n# Channel\nprint('Channel:', chrom.channel)\n# Injection time\nprint('Injection time:', chrom.injection_time)\n# Unit\nprint('Signal Unit:', chrom.signal_unit)\n</pre> # data print(chrom.data.head()) # metadata print(chrom.metadata.keys()) # Channel print('Channel:', chrom.channel) # Injection time print('Injection time:', chrom.injection_time) # Unit print('Signal Unit:', chrom.signal_unit) <pre>   Time (min)  Value (pA)\n0    0.000667    7.365880\n1    0.001333    7.364733\n2    0.002000    7.364567\n3    0.002667    7.364584\n4    0.003333    7.364558\ndict_keys(['\\ufeffURL', 'Channel', 'Data Vault', 'Sequence', 'Number', 'Position', 'Processing Method', 'Instrument Method', 'Type', 'Status', 'Inject Time', 'Volume (\u00b5l)', 'Dilution Factor', 'Weight', 'Time Min. (min)', 'Time Max. (min)', 'Data Points', 'Detector', 'Generating Data System', 'Exporting Data System', 'Operator', 'Signal Unit', 'Signal Min.', 'Signal Max.', 'Driver Name', 'Channel Type', 'Min. Step (s)', 'Max. Step (s)', 'Average Step (s)', 'time_unit'])\nChannel: FID_right\nInjection time: 2025-01-14 18:13:58\nSignal Unit: pA\n</pre> <p>When doing on-line GC, you will have more than one chromatogram, potentially also from multiple channels.</p> <p>Therefore, we first set up an 'Experiment' object, to which we will add our chromatograms. Chromatograms can be added using the 'add_chromatogram' method. We can add the chromatogram directly from the path, or parse it first. The method automatically infers the channel of the chromatogram, although you can override this. Notice how calling 'Exp.channel_names' gives the list of channels.</p> In\u00a0[19]: Copied! <pre>Exp = cs.Experiment(name=\"Quickstart Example\")\nExp.add_chromatogram(chrom_list[0])\n# or alternatively:\n# Exp.add_chromatogram(chrom) \n# when you parsed the chromatogram beforehand\n\nprint(Exp.channel_names)\n</pre> Exp = cs.Experiment(name=\"Quickstart Example\") Exp.add_chromatogram(chrom_list[0]) # or alternatively: # Exp.add_chromatogram(chrom)  # when you parsed the chromatogram beforehand  print(Exp.channel_names) <pre>['FID_right']\n</pre> <p>Let's add all chromatograms for the calibration run to the experiment. We now have two different channels in the experiment:</p> In\u00a0[20]: Copied! <pre>Exp_full = cs.Experiment(name=\"Quickstart Example 2\")\nfor chrom_path in chrom_list:\n    Exp_full.add_chromatogram(chrom_path)\n\nprint(Exp_full.channel_names)  # summary of the experiment\n</pre> Exp_full = cs.Experiment(name=\"Quickstart Example 2\") for chrom_path in chrom_list:     Exp_full.add_chromatogram(chrom_path)  print(Exp_full.channel_names)  # summary of the experiment <pre>['FID_right', 'TCD']\n</pre> <p>Channels can be accessed using the .channels method with their name. From there, you can access chromatograms by index:</p> In\u00a0[21]: Copied! <pre>Exp_full.channels['FID_right'].chromatograms[0].data.head()\n</pre> Exp_full.channels['FID_right'].chromatograms[0].data.head() Out[21]: Time (min) Value (pA) 0 0.000667 7.365880 1 0.001333 7.364733 2 0.002000 7.364567 3 0.002667 7.364584 4 0.003333 7.364558 <p>This way you have access to all chromatograms with just one line.</p> In\u00a0[22]: Copied! <pre># Experiment:\n%matplotlib widget\nExp_full.plot_chromatograms()\n</pre> # Experiment: %matplotlib widget Exp_full.plot_chromatograms()                      Figure                  In\u00a0[23]: Copied! <pre># Channel:\nExp_full.channels['FID_right'].plot()\n</pre> # Channel: Exp_full.channels['FID_right'].plot() Out[23]: <pre>&lt;Axes: title={'center': 'Channel: FID_right'}, xlabel='Time (min)', ylabel='Value (pA)'&gt;</pre>                      Figure                  In\u00a0[24]: Copied! <pre># Chromatogram:\nExp_full.channels['FID_right'].chromatograms[0].plot()\n</pre> # Chromatogram: Exp_full.channels['FID_right'].chromatograms[0].plot() Out[24]: <pre>&lt;Axes: title={'center': 'Chromatogram - FID_right - ../../dev_data/chroms/pyGCMS_calibration/calibration_20250114_no1/10_FID_right.txt'}, xlabel='Time (min)', ylabel='Value (pA)'&gt;</pre>                      Figure                  In\u00a0[25]: Copied! <pre>print(cs.list_baseline_functions())\n</pre> print(cs.list_baseline_functions()) <pre>min_subtract\ntime_window_baseline\ntime_point_baseline\nlinear_baseline\n</pre> <p>To showcase how adding a custom baseline works, we are going to reproduce the min_subtract function. The function needs to take as input the dataframe of the chromatogram, and return the baseline-corrected signal. The apply_baseline method will add a new column to the chromatogram.data df. If you instead want to overwrite the existing data, use 'inplace=True'. This feature is turned off by default.</p> In\u00a0[26]: Copied! <pre>import pandas as pd\n\ndef min_subtract2(data: pd.DataFrame) -&gt; pd.Series:\n    signal = data[data.columns[1]]\n    return signal - signal.min()\n\nchrom2 = Exp_full.channels['FID_right'].chromatograms[3]\nchrom2.apply_baseline(min_subtract2)\n\n# To overwrite the data, use:\n# chrom2.apply_baseline(min_subtract2, inplace=True)\n\nchrom2.data.head()\n</pre> import pandas as pd  def min_subtract2(data: pd.DataFrame) -&gt; pd.Series:     signal = data[data.columns[1]]     return signal - signal.min()  chrom2 = Exp_full.channels['FID_right'].chromatograms[3] chrom2.apply_baseline(min_subtract2)  # To overwrite the data, use: # chrom2.apply_baseline(min_subtract2, inplace=True)  chrom2.data.head() Out[26]: Time (min) Value (pA) Value (pA)_BLcorr 0 0.000667 7.372743 0.020986 1 0.001333 7.367826 0.016069 2 0.002000 7.368490 0.016733 3 0.002667 7.368260 0.016503 4 0.003333 7.368131 0.016374 <p>A couple simple baseline functions are included in the package. You can print the documention of each one using the <code>.__doc__</code> method.</p> In\u00a0[51]: Copied! <pre>print('Availible baselines:\\n',\n      cs.list_baseline_functions())\n\nprint('\\nExample:'\n        '\\nLinear baseline: ',\n        cs.linear_baseline.__doc__)\n</pre> print('Availible baselines:\\n',       cs.list_baseline_functions())  print('\\nExample:'         '\\nLinear baseline: ',         cs.linear_baseline.__doc__) <pre>Availible baselines:\n min_subtract\ntime_window_baseline\ntime_point_baseline\nlinear_baseline\n\nExample:\nLinear baseline:  \n    Subtract a linear baseline defined by two time points.\n    Determines a linear baseline between the signal values at the two specified time points.\n\n    Args:\n        data: DataFrame containing time and signal columns\n        start_time: Time point to define the start of the baseline. Use the same unit as the chromatogram.\n        end_time: Time point to define the end of the baseline. Use the same unit as the chromatogram.\n\n    Returns:\n        Corrected signal as pandas Series\n    \n</pre> <p>This means we can just import the function from the package, and check whether it is good enough. Note that in this example the baseline is very flat and the signal very strong.</p> In\u00a0[28]: Copied! <pre>import matplotlib.pyplot as plt\n%matplotlib widget\nfrom chromstream.data_processing import min_subtract\n\nchrom2.apply_baseline(min_subtract)\nfig, ax = plt.subplots(figsize=(3.3, 3.3/1.618))\nchrom2.plot(ax=ax)\nchrom2.plot(column='Value (pA)_BLcorr', ax=ax, color='orange')\nax.set_title('')\nax.set_ylim(0, 200)\nax.set_xlim(1.8, 3.2)\nax.legend(['Original', 'BL corrected'], frameon=False)\nplt.show()\n</pre> import matplotlib.pyplot as plt %matplotlib widget from chromstream.data_processing import min_subtract  chrom2.apply_baseline(min_subtract) fig, ax = plt.subplots(figsize=(3.3, 3.3/1.618)) chrom2.plot(ax=ax) chrom2.plot(column='Value (pA)_BLcorr', ax=ax, color='orange') ax.set_title('') ax.set_ylim(0, 200) ax.set_xlim(1.8, 3.2) ax.legend(['Original', 'BL corrected'], frameon=False) plt.show()                      Figure                  In\u00a0[29]: Copied! <pre>Peaks = {'Methane_Ethane':[1.93,1.99], 'Propane':[1.99,2.04], 'Butane': [2.085,2.16], 'Pentane':[2.325,2.385]}\nintegral_list = []\nchrom2.apply_baseline(min_subtract, inplace=True)\nintegrals_single = chrom2.integrate_peaks(Peaks)\n#printing results:\nprint(integrals_single)\n# showing as dataframe:\npd.DataFrame([integrals_single])\n</pre> Peaks = {'Methane_Ethane':[1.93,1.99], 'Propane':[1.99,2.04], 'Butane': [2.085,2.16], 'Pentane':[2.325,2.385]} integral_list = [] chrom2.apply_baseline(min_subtract, inplace=True) integrals_single = chrom2.integrate_peaks(Peaks) #printing results: print(integrals_single) # showing as dataframe: pd.DataFrame([integrals_single]) <pre>{'Timestamp': Timestamp('2025-01-14 19:45:09'), 'Methane_Ethane': np.float64(11.70935060763651), 'Propane': np.float64(103.54438043609807), 'Butane': np.float64(46.19299856635804), 'Pentane': np.float64(10.331378662427008)}\n</pre> Out[29]: Timestamp Methane_Ethane Propane Butane Pentane 0 2025-01-14 19:45:09 11.709351 103.54438 46.192999 10.331379 <p>When integrating a channel, we apply the baseline to the whole dataset first, then integrate:</p> In\u00a0[30]: Copied! <pre>Exp_full.channels['FID_right'].apply_baseline(min_subtract, inplace=True)\nintegrals_full = Exp_full.channels['FID_right'].integrate_peaks(Peaks)\nintegrals_full.sort_values('Timestamp').reset_index(drop=True)\n</pre> Exp_full.channels['FID_right'].apply_baseline(min_subtract, inplace=True) integrals_full = Exp_full.channels['FID_right'].integrate_peaks(Peaks) integrals_full.sort_values('Timestamp').reset_index(drop=True) Out[30]: Timestamp Methane_Ethane Propane Butane Pentane 0 2025-01-14 13:41:40 0.002406 0.002037 0.003068 0.002265 1 2025-01-14 14:09:55 10.752795 94.976175 42.308592 9.436128 2 2025-01-14 14:41:08 11.805789 104.235329 46.425401 10.362865 3 2025-01-14 15:11:33 11.915303 105.252292 46.925896 10.486735 4 2025-01-14 15:41:56 11.920735 105.291477 46.955402 10.498406 5 2025-01-14 16:12:20 11.915414 105.249754 46.937924 10.496388 6 2025-01-14 16:42:44 11.929328 105.329486 46.968685 10.503923 7 2025-01-14 17:13:09 11.868515 104.824002 46.752611 10.455457 8 2025-01-14 17:43:33 11.841344 104.603074 46.648921 10.434957 9 2025-01-14 18:13:58 11.764285 103.999964 46.393107 10.375813 10 2025-01-14 18:44:21 11.751355 104.012372 46.623499 10.389485 11 2025-01-14 19:14:45 11.739205 104.021312 46.440668 10.388778 12 2025-01-14 19:45:09 11.709351 103.544380 46.192999 10.331379 13 2025-01-14 20:15:34 11.687028 103.337315 46.082484 10.301935 14 2025-01-14 20:45:58 11.811591 104.370643 46.530247 10.401583 In\u00a0[31]: Copied! <pre>testdata = Path(\"../..\") / \"dev_data\" / \"chroms\" /  \"pyGCMS_calibration\" / \"calibration_20250114_no1\" # data location\nchrom_list = testdata.iterdir() #list of chromatograms\n\nExp_full = cs.Experiment(name=\"Quickstart Example 2\") # create experiment\nfor chrom_path in chrom_list: \n    Exp_full.add_chromatogram(chrom_path) # adding each chromatograms to the experiment\n\nPeaks = {'Methane_Ethane':[1.93,1.99], 'Propane':[1.99,2.04], 'Butane': [2.085,2.16], 'Pentane':[2.325,2.385]} # setting the peak boundaries\n\nExp_full.channels['FID_right'].apply_baseline(min_subtract, inplace=True) # applying a baseline\nintegrals_full = Exp_full.channels['FID_right'].integrate_peaks(Peaks) # integrating peaks\nintegrals_full.sort_values('Timestamp').reset_index(drop=True) # sorting and showing the integration results\n</pre> testdata = Path(\"../..\") / \"dev_data\" / \"chroms\" /  \"pyGCMS_calibration\" / \"calibration_20250114_no1\" # data location chrom_list = testdata.iterdir() #list of chromatograms  Exp_full = cs.Experiment(name=\"Quickstart Example 2\") # create experiment for chrom_path in chrom_list:      Exp_full.add_chromatogram(chrom_path) # adding each chromatograms to the experiment  Peaks = {'Methane_Ethane':[1.93,1.99], 'Propane':[1.99,2.04], 'Butane': [2.085,2.16], 'Pentane':[2.325,2.385]} # setting the peak boundaries  Exp_full.channels['FID_right'].apply_baseline(min_subtract, inplace=True) # applying a baseline integrals_full = Exp_full.channels['FID_right'].integrate_peaks(Peaks) # integrating peaks integrals_full.sort_values('Timestamp').reset_index(drop=True) # sorting and showing the integration results Out[31]: Timestamp Methane_Ethane Propane Butane Pentane 0 2025-01-14 13:41:40 0.002406 0.002037 0.003068 0.002265 1 2025-01-14 14:09:55 10.752795 94.976175 42.308592 9.436128 2 2025-01-14 14:41:08 11.805789 104.235329 46.425401 10.362865 3 2025-01-14 15:11:33 11.915303 105.252292 46.925896 10.486735 4 2025-01-14 15:41:56 11.920735 105.291477 46.955402 10.498406 5 2025-01-14 16:12:20 11.915414 105.249754 46.937924 10.496388 6 2025-01-14 16:42:44 11.929328 105.329486 46.968685 10.503923 7 2025-01-14 17:13:09 11.868515 104.824002 46.752611 10.455457 8 2025-01-14 17:43:33 11.841344 104.603074 46.648921 10.434957 9 2025-01-14 18:13:58 11.764285 103.999964 46.393107 10.375813 10 2025-01-14 18:44:21 11.751355 104.012372 46.623499 10.389485 11 2025-01-14 19:14:45 11.739205 104.021312 46.440668 10.388778 12 2025-01-14 19:45:09 11.709351 103.544380 46.192999 10.331379 13 2025-01-14 20:15:34 11.687028 103.337315 46.082484 10.301935 14 2025-01-14 20:45:58 11.811591 104.370643 46.530247 10.401583"},{"location":"notebooks/Quickstart.html#quickstart","title":"Quickstart\u00b6","text":"<p>This notebook will help you get started with ChromStream quickly. It covers setting up an experiment, adding chromatograms to it, plotting and integrating.</p>"},{"location":"notebooks/Quickstart.html#setting-up-and-parsing","title":"Setting up and parsing\u00b6","text":"<p>ChromStream uses a 3-tier system for accessing data:</p> <ul> <li>Experiment: Contains all data, including e.g. log files</li> <li>Channel: Contains the chromatograms of a given detector/channel</li> <li>Chromatogram: Contains raw data and metadata of an individual chromatogram</li> </ul> <p>Chromatograms can be parsed individually, or directly added to an experiment. To get started, let's parse a single chromatogram from the testing data included in this repo.</p>"},{"location":"notebooks/Quickstart.html#plotting","title":"Plotting\u00b6","text":"<p>The first thing you generally want to do is look at your chromatograms. This can be done at all levels, from experiment to single chromatogram. Note that the experiment uses 'plot_chromatograms' instead of 'plot'. Hint: To make the plots interactive, add</p> <pre>%matplotlib widget\n</pre> <p>to the cell.</p>"},{"location":"notebooks/Quickstart.html#baseline-subtraction","title":"Baseline subtraction\u00b6","text":"<p>The baselines of chromatograms can vary a lot. Therefore, ChromStream allows you to use custom baseline functions.</p>"},{"location":"notebooks/Quickstart.html#integration","title":"Integration\u00b6","text":"<p>In the current implementation, peaks are integrated in specified boundaries. Good separation is therefore critical if you want to isolate specific compounds. You can integrate both a single chromatogram, as well as a full channel, using the .integrate_peaks() method and a peaklist provided as a dict: To make things easier, we use the baseline subtraction with the overwrite set to True. For a single chromatogram, the integration gives a dictionary with the timestamp of the injection:</p>"},{"location":"notebooks/Quickstart.html#full-processing","title":"Full processing\u00b6","text":"<p>Putting everything shown above together, we can do a full processing of our data in just 9 lines:</p>"},{"location":"notebooks/cracking_example.html","title":"Small Hydrocarbon Cracking","text":"In\u00a0[67]: Copied! <pre>import chromstream as cs\nimport pandas as pd\nfrom pathlib import Path\nfrom chromstream.data_processing import time_window_baseline\n</pre> import chromstream as cs import pandas as pd from pathlib import Path from chromstream.data_processing import time_window_baseline In\u00a0[68]: Copied! <pre>data_home = Path(\"../..\") / \"dev_data\" / \"chroms\" /  \"MTO_setup\"\npaths_all = sorted((data_home).iterdir())\n# Initialize an Experiment\nexp_mto = cs.Experiment(\"Cracking test\")\n\nfor path in paths_all:\n    Chrom1, Chrom2, Chrom3 = cs.parse_MTO_asc(path)\n    # Applying baseline (mean in a specified time window)\n    Chrom1.apply_baseline(time_window_baseline, time_window=(288,294),inplace=True)\n    Chrom2.apply_baseline(time_window_baseline, time_window=(288,294),inplace=True)\n    Chrom3.apply_baseline(time_window_baseline, time_window=(10,15),inplace=True)\n    # Adding chromatograms to the experiment\n    exp_mto.add_chromatogram(Chrom1)\n    exp_mto.add_chromatogram(Chrom2)\n    exp_mto.add_chromatogram(Chrom3)\n</pre> data_home = Path(\"../..\") / \"dev_data\" / \"chroms\" /  \"MTO_setup\" paths_all = sorted((data_home).iterdir()) # Initialize an Experiment exp_mto = cs.Experiment(\"Cracking test\")  for path in paths_all:     Chrom1, Chrom2, Chrom3 = cs.parse_MTO_asc(path)     # Applying baseline (mean in a specified time window)     Chrom1.apply_baseline(time_window_baseline, time_window=(288,294),inplace=True)     Chrom2.apply_baseline(time_window_baseline, time_window=(288,294),inplace=True)     Chrom3.apply_baseline(time_window_baseline, time_window=(10,15),inplace=True)     # Adding chromatograms to the experiment     exp_mto.add_chromatogram(Chrom1)     exp_mto.add_chromatogram(Chrom2)     exp_mto.add_chromatogram(Chrom3) <p>We can get a quick look at the chromatograms using the integrated plotting method:</p> In\u00a0[69]: Copied! <pre>exp_mto.plot_chromatograms()\n</pre> exp_mto.plot_chromatograms() <p>We parse the corresponding log file and also add it to the experiment object. This enables the access to the log data from the Experiment object. You can try if the general log file parser included in this package (cs.parse_log_file()) can handle your logfile. If not, you can also feed a pandas dataframe to the .add_log() method. To enable other functionality, this dataframe must contain a 'Timestamp' column containing pd.DataTime objects.</p> In\u00a0[70]: Copied! <pre>log_path = Path(\"../..\")/ \"dev_data\" / \"logs\" / \"MTO\"\nlogs = sorted((log_path).iterdir())\nlog_data = cs.parse_log_MTO(logs[0])\nexp_mto.add_log(log_data)\n</pre> log_path = Path(\"../..\")/ \"dev_data\" / \"logs\" / \"MTO\" logs = sorted((log_path).iterdir()) log_data = cs.parse_log_MTO(logs[0]) exp_mto.add_log(log_data) <p>With all channels parsed, we can now begin integrating the data. For this we can use the .integrate peaks method. A peak is described by a dict with integration boundries, which need to be specified manually. The resulting unit of the integral is the the unit of the signal multiplied by the recorded unit of the retention time. Some programs save in minutes, while others in seconds. Keep track of your units.</p> In\u00a0[71]: Copied! <pre>Peaks_FID_L = {'DMP_L': [17.7,24], 'Rest': [14,17.7]}\n\nPeaks_FID_M = {'DMP': [255,280],\n               'Butane': [34,38],\n               'Propane': [29,34],\n               'Ethane': [27.87,29.26],\n               'Methane': [27.5,27.87],\n               'ALL_products':[26,150]}\n\nPeaks_TCD = {\"N2\": [20, 26], \"H2\": [16, 19]}\n\nintegrals_FID_L = exp_mto.channels['FID_L'].integrate_peaks(peaklist=Peaks_FID_L,).set_index('Timestamp')\nintegrals_FID_M = exp_mto.channels['FID_M'].integrate_peaks(peaklist=Peaks_FID_M,).set_index('Timestamp')\nintegrals_TCD = exp_mto.channels['TCD'].integrate_peaks(peaklist=Peaks_TCD,).set_index('Timestamp')\n</pre> Peaks_FID_L = {'DMP_L': [17.7,24], 'Rest': [14,17.7]}  Peaks_FID_M = {'DMP': [255,280],                'Butane': [34,38],                'Propane': [29,34],                'Ethane': [27.87,29.26],                'Methane': [27.5,27.87],                'ALL_products':[26,150]}  Peaks_TCD = {\"N2\": [20, 26], \"H2\": [16, 19]}  integrals_FID_L = exp_mto.channels['FID_L'].integrate_peaks(peaklist=Peaks_FID_L,).set_index('Timestamp') integrals_FID_M = exp_mto.channels['FID_M'].integrate_peaks(peaklist=Peaks_FID_M,).set_index('Timestamp') integrals_TCD = exp_mto.channels['TCD'].integrate_peaks(peaklist=Peaks_TCD,).set_index('Timestamp')  <p>We then combine all integrated channels to an 'Analysis' dataframe. We then add extra data from the logfile using the dedicated cs.get_temp_and_valves_MTO method. For a more general approach, you can use the function below as follows:</p> <pre>new_df = cs.add_log_data(Analysis, Log_data)\n</pre> <p>This function takes in a dataframe containing a timestamp column, and adds entries from the Log_data file at the appropriate time. Note that this approach relies on the the log data having signifcantly better time resolution.</p> <p>We also begin to filter the experiment, in this case we skip the heatup phase of the reactor by only including the data where the carrier gas is flown into the saturator. The last five time injections are skipped, and the experiment start time is set.</p> In\u00a0[72]: Copied! <pre># import chromstream.data_processing as csd\n\n# Combining all integral frames for analysis\nAnalysis = pd.concat([integrals_FID_L, integrals_FID_M, integrals_TCD], axis=1)\n# Adding log data\nAnalysis = cs.get_temp_and_valves_MTO(Analysis, exp_mto.log)\n\nAnalysis = Analysis[Analysis['v10-bubbler'] == 1] # skip the heatup phase, experiemnts starts when the flow over the bubbler is started\n# Setting experiment start time\nexp_mto.experiment_starttime = Analysis.index.min()\n# Add an 'Experiment_time' column in minutes\nAnalysis['Experiment_time(min)'] = (Analysis.index - exp_mto.experiment_starttime).total_seconds() / 60.0 # type: ignore\n# dropping the last couple datapoints\nAnalysis = Analysis[:-5]\n</pre> # import chromstream.data_processing as csd  # Combining all integral frames for analysis Analysis = pd.concat([integrals_FID_L, integrals_FID_M, integrals_TCD], axis=1) # Adding log data Analysis = cs.get_temp_and_valves_MTO(Analysis, exp_mto.log)  Analysis = Analysis[Analysis['v10-bubbler'] == 1] # skip the heatup phase, experiemnts starts when the flow over the bubbler is started # Setting experiment start time exp_mto.experiment_starttime = Analysis.index.min() # Add an 'Experiment_time' column in minutes Analysis['Experiment_time(min)'] = (Analysis.index - exp_mto.experiment_starttime).total_seconds() / 60.0 # type: ignore # dropping the last couple datapoints Analysis = Analysis[:-5] In\u00a0[73]: Copied! <pre>Analysis\n</pre> Analysis Out[73]: DMP_L Rest DMP Butane Propane Ethane Methane ALL_products N2 H2 Oven Temperature v10-bubbler v11-reactor Experiment_time(min) Timestamp 2024-01-19 19:44:55 31392.331793 1.452073 246.772513 2.376192 -3.162931 -2.803507 -0.143770 7.100620 1.071223e+06 -0.409145 515.0 1.0 bypass 0.000000 2024-01-19 19:50:16 31560.053130 8.138823 282.637634 7.887359 10.861992 1.449078 0.868808 -25.423855 1.146308e+06 -40.037706 515.0 1.0 bypass 5.350000 2024-01-19 19:55:36 31368.433294 11.894537 357.290991 -19.914750 -22.487561 -6.191677 -1.293394 -276.501135 1.172510e+06 -19.233478 515.0 1.0 bypass 10.683333 2024-01-19 20:00:55 31746.996460 13.234923 329.950408 2.968576 5.372190 1.232824 0.518902 147.709408 1.196526e+06 -30.714600 515.0 1.0 bypass 16.000000 2024-01-19 20:06:15 31470.195805 16.970003 304.686298 -6.486272 -4.417520 -0.551716 0.081403 -132.612736 1.190216e+06 48.346224 515.0 1.0 bypass 21.333333 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2024-01-20 00:54:09 29030.636607 1191.277744 275.294602 84.151802 169.262932 4.652743 4.428170 232.036995 1.167079e+06 44.945459 470.0 1.0 reactor 309.233333 2024-01-20 00:59:28 29141.897629 1182.424599 247.177863 83.922170 168.006746 4.658534 4.447539 273.574226 1.169290e+06 -92.358158 470.0 1.0 reactor 314.550000 2024-01-20 01:04:49 28927.047823 1146.061409 312.909119 87.792633 174.100380 6.391157 4.666055 236.998909 1.165463e+06 84.385915 470.0 1.0 reactor 319.900000 2024-01-20 01:10:08 29359.699771 1207.711274 334.908662 117.485047 208.999649 14.679075 6.315013 979.032896 1.179302e+06 17.168660 470.0 1.0 reactor 325.216667 2024-01-20 01:15:29 29301.926361 1206.387395 274.164014 93.430265 181.066416 9.549296 5.129579 585.681963 1.180314e+06 -74.513729 470.0 1.0 reactor 330.566667 <p>63 rows \u00d7 14 columns</p> <p>Lets take a look at the data we have so far by plotting the raw integral of the DMP compound on the FID_L channel. The reaction is conducted using a multi-step temperature programm to investigate the effect of the temperature on the conversion.</p> In\u00a0[74]: Copied! <pre>import matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax2 = ax.twinx()\n\nax.plot(Analysis['Experiment_time(min)'], Analysis['DMP_L'], label='DMP_L', color='C0', marker='o')\nax2.plot(Analysis['Experiment_time(min)'], Analysis['Oven Temperature'], color='C1', label='Oven Temp', linestyle='--')\n\nax.set_xlabel('Time (min)')\nax.set_ylabel(f'Integral ({exp_mto.channels[\"FID_L\"].chromatograms[0].signal_unit}*{exp_mto.channels[\"FID_L\"].chromatograms[0].time_unit})')\nax2.set_ylabel('Oven Temperature (\u00b0C)')\n</pre> import matplotlib.pyplot as plt fig, ax = plt.subplots() ax2 = ax.twinx()  ax.plot(Analysis['Experiment_time(min)'], Analysis['DMP_L'], label='DMP_L', color='C0', marker='o') ax2.plot(Analysis['Experiment_time(min)'], Analysis['Oven Temperature'], color='C1', label='Oven Temp', linestyle='--')  ax.set_xlabel('Time (min)') ax.set_ylabel(f'Integral ({exp_mto.channels[\"FID_L\"].chromatograms[0].signal_unit}*{exp_mto.channels[\"FID_L\"].chromatograms[0].time_unit})') ax2.set_ylabel('Oven Temperature (\u00b0C)') Out[74]: <pre>Text(0, 0.5, 'Oven Temperature (\u00b0C)')</pre> <p>Working with absolute values is not ideal, so lets normalize the data. In this example we initally dont care about absolute units, as we only investigate conversion. To normalize, the area of the DMP peak in the last 5 chromatograms where the the v11 valve is set to bypass is obtained, so that the DMP flow goes straight to the GC, rather than the reactor.</p> In\u00a0[75]: Copied! <pre>no_chromatograms_norm = 5 # we normalize by the last 5 chromatograms\nidx = Analysis[Analysis['v11-reactor'] == 'bypass'].index # get the indeces in the integral frame where the reactor is bypassed\nidx_norm = idx[-(no_chromatograms_norm+1):-1]\nnorm_DMP_L = Analysis['DMP_L'][idx_norm].mean() \n\nfig, ax = plt.subplots()\nax.plot(Analysis['Experiment_time(min)'], 100*Analysis['DMP_L']/norm_DMP_L, label='DMP_L normalized',marker='o', color='C0')\nax.set_xlabel('Time (min)')\nax.set_ylabel('Normalized Integral (%)')\nax.set_ylim(80, )\n</pre> no_chromatograms_norm = 5 # we normalize by the last 5 chromatograms idx = Analysis[Analysis['v11-reactor'] == 'bypass'].index # get the indeces in the integral frame where the reactor is bypassed idx_norm = idx[-(no_chromatograms_norm+1):-1] norm_DMP_L = Analysis['DMP_L'][idx_norm].mean()   fig, ax = plt.subplots() ax.plot(Analysis['Experiment_time(min)'], 100*Analysis['DMP_L']/norm_DMP_L, label='DMP_L normalized',marker='o', color='C0') ax.set_xlabel('Time (min)') ax.set_ylabel('Normalized Integral (%)') ax.set_ylim(80, ) Out[75]: <pre>(80.0, 102.5347920562692)</pre> <p>The data is still quite noisy. The problem is the following: We bubble 1.5 mL N2 though a DMP saturator, which then gets diluted by 50 mL He. This means that a small deviation of the N2 mass flow controller can have a big effect. However, because we can detect N2 on the TCD channel of the GC, we can use it to correct for this effect! Lets also add the integral of the products and the reactor temperature on the second axis.</p> In\u00a0[76]: Copied! <pre>fig, ax = plt.subplots(tight_layout=True)\n\nAnalysis['N2corr']= Analysis['N2']/Analysis.loc[idx_norm]['N2'].mean()\nAnalysis['Conversion_norm'] = Analysis['DMP_L']/norm_DMP_L*100/Analysis['N2corr']\nAnalysis['Products_norm'] = Analysis['Rest']/norm_DMP_L*100/Analysis['N2corr']\n\nax.plot(Analysis['Experiment_time(min)'],Analysis['Conversion_norm'],label='Dimethylpentane',marker = 'o')\nax.plot(Analysis['Experiment_time(min)'],Analysis['Products_norm'],label='Products',marker = 'o')\n\nax.set_xlabel('Time (min)')\nax.set_ylabel('DMP concentration (%)')\nax.set_xlim(0,335)\nax.set_ylim(0,105)\n\n#plotting the temperature\nax2 = ax.twinx()\nax2.plot(Analysis['Experiment_time(min)'], Analysis['Oven Temperature'], label='Temperature',color='black', linestyle = '--')\n\n# Note: You can also plot the log directly, it will have a higher time resolution\n# temp_df = exp_mto.log[['Timestamp', 'Oven Temperature']]\n# temp_df['Experiment_time(min)'] = (temp_df['Timestamp'] - exp_mto.experiment_starttime).dt.total_seconds() / 60.0 # type: ignore\n# ax2.plot(temp_df['Experiment_time(min)'], temp_df['Oven Temperature'], label='Temperature',color='gray', linestyle = '--', alpha=0.5)\n\nax2.set_ylabel('Temperature (\u00b0C)')\nax.legend(frameon=False)\nplt.show()\n</pre> fig, ax = plt.subplots(tight_layout=True)  Analysis['N2corr']= Analysis['N2']/Analysis.loc[idx_norm]['N2'].mean() Analysis['Conversion_norm'] = Analysis['DMP_L']/norm_DMP_L*100/Analysis['N2corr'] Analysis['Products_norm'] = Analysis['Rest']/norm_DMP_L*100/Analysis['N2corr']  ax.plot(Analysis['Experiment_time(min)'],Analysis['Conversion_norm'],label='Dimethylpentane',marker = 'o') ax.plot(Analysis['Experiment_time(min)'],Analysis['Products_norm'],label='Products',marker = 'o')  ax.set_xlabel('Time (min)') ax.set_ylabel('DMP concentration (%)') ax.set_xlim(0,335) ax.set_ylim(0,105)  #plotting the temperature ax2 = ax.twinx() ax2.plot(Analysis['Experiment_time(min)'], Analysis['Oven Temperature'], label='Temperature',color='black', linestyle = '--')  # Note: You can also plot the log directly, it will have a higher time resolution # temp_df = exp_mto.log[['Timestamp', 'Oven Temperature']] # temp_df['Experiment_time(min)'] = (temp_df['Timestamp'] - exp_mto.experiment_starttime).dt.total_seconds() / 60.0 # type: ignore # ax2.plot(temp_df['Experiment_time(min)'], temp_df['Oven Temperature'], label='Temperature',color='gray', linestyle = '--', alpha=0.5)  ax2.set_ylabel('Temperature (\u00b0C)') ax.legend(frameon=False) plt.show() <p>As you can see the data is not singficantly less noisy, and we can read out the conversion at different temperatures. To get more quantitaive results, we will requiere the partial pressure of DMP entering the reactor. With a calibration we can determine first the vol% and then the partial pressure of DMP at the start of the experiment as follows:</p> In\u00a0[77]: Copied! <pre>import numpy as np\n# CF = peak_area/concentration, so concentration = peak_area/CF\n# The *7 accounts for the 7 carbon atoms in DMP (dimethylpentane)\ncalibration_factor = 7463915.174603943 *7 \nvol_pct = norm_DMP_L / calibration_factor  # see the calibration notebook for determination of the calibration factor.\npartial_pressure_kpa = vol_pct*10**6/100 # assuming 10^6 pa normal pressure\n\nprint('The volume fraction is ' +str(np.round(vol_pct*100,4)) + '%') # in Pa\nprint('The pressure of DMP is ' +str(np.round(partial_pressure_kpa,4)) + ' kPa') # in kPa\n</pre> import numpy as np # CF = peak_area/concentration, so concentration = peak_area/CF # The *7 accounts for the 7 carbon atoms in DMP (dimethylpentane) calibration_factor = 7463915.174603943 *7  vol_pct = norm_DMP_L / calibration_factor  # see the calibration notebook for determination of the calibration factor. partial_pressure_kpa = vol_pct*10**6/100 # assuming 10^6 pa normal pressure  print('The volume fraction is ' +str(np.round(vol_pct*100,4)) + '%') # in Pa print('The pressure of DMP is ' +str(np.round(partial_pressure_kpa,4)) + ' kPa') # in kPa <pre>The volume fraction is 0.0598%\nThe pressure of DMP is 5.9799 kPa\n</pre>"},{"location":"notebooks/cracking_example.html#small-hydrocarbon-cracking","title":"Small Hydrocarbon Cracking\u00b6","text":"<p>This Notebook showcases a typical application of on-line GC using the cracking of 2,4 dimethylpentane with a zeolite catalyst as an exmple.</p>"},{"location":"notebooks/cracking_example.html#setup-and-parsing","title":"Setup and Parsing\u00b6","text":"<p>We first set up an Experiment object and add the chromatograms to it. The GC used here generates ASCII files that contains chromatograms of all three channels, and therefore require a dedicated parser. As a baseline, the mean value in a specified time window is subtracted.</p>"},{"location":"notebooks/example_calibration.html","title":"Online GC Calibration","text":"<p>For details regarding the processing of data from this setup setup check the dedicated Notebook. Here we use a bottle with components from Methane to Pentane as well as Hydrogen diluted by Nitrogen. We set up an Experiment object and add all calibration chromatograms to it, subtracting the average signal in a specifed time window as a baseline.</p> In\u00a0[1]: Copied! <pre>from chromstream.objects import Experiment\nfrom chromstream.data_processing import time_window_baseline\nfrom pathlib import Path\nimport pandas as pd\nimport chromstream.parsers as csp\nimport matplotlib.pyplot as plt\n</pre> from chromstream.objects import Experiment from chromstream.data_processing import time_window_baseline from pathlib import Path import pandas as pd import chromstream.parsers as csp import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>data_home = Path(\"../..\")/\"dev_data\" / \"chroms\" /  \"MTO_calibration\"\npaths_all = sorted((data_home).iterdir())\n# Initialize an Experiment\nexp_mto = Experiment(\"MTO_calib\")\n\nfor path in paths_all:\n    Chrom1, Chrom2, Chrom3 = csp.parse_MTO_asc(path)\n    # Applying baseline (mean in a specified time window)\n    Chrom1.apply_baseline(time_window_baseline, time_window=(288,294),inplace=True)\n    Chrom2.apply_baseline(time_window_baseline, time_window=(288,294),inplace=True)\n    Chrom3.apply_baseline(time_window_baseline, time_window=(10,15),inplace=True)\n    # Adding chromatograms to the experiment\n    exp_mto.add_chromatogram(Chrom1)\n    exp_mto.add_chromatogram(Chrom2)\n    exp_mto.add_chromatogram(Chrom3)\n</pre> data_home = Path(\"../..\")/\"dev_data\" / \"chroms\" /  \"MTO_calibration\" paths_all = sorted((data_home).iterdir()) # Initialize an Experiment exp_mto = Experiment(\"MTO_calib\")  for path in paths_all:     Chrom1, Chrom2, Chrom3 = csp.parse_MTO_asc(path)     # Applying baseline (mean in a specified time window)     Chrom1.apply_baseline(time_window_baseline, time_window=(288,294),inplace=True)     Chrom2.apply_baseline(time_window_baseline, time_window=(288,294),inplace=True)     Chrom3.apply_baseline(time_window_baseline, time_window=(10,15),inplace=True)     # Adding chromatograms to the experiment     exp_mto.add_chromatogram(Chrom1)     exp_mto.add_chromatogram(Chrom2)     exp_mto.add_chromatogram(Chrom3) <p>Briefly plotting the chromatograms:</p> In\u00a0[3]: Copied! <pre>fig, axs = plt.subplots(3,1, figsize=(7,7/1.618))\nexp_mto.plot_chromatograms(ax=axs)\nplt.tight_layout()\naxs[0].set_ylim(-100000,)\naxs[0].set_xlim(15,60)\n\naxs[1].set_xlim(15,60)\naxs[1].set_ylim(0,200000)\n\naxs[2].set_ylim(0,200000)\naxs[2].set_xlim(10,60)\nplt.show()\n</pre> fig, axs = plt.subplots(3,1, figsize=(7,7/1.618)) exp_mto.plot_chromatograms(ax=axs) plt.tight_layout() axs[0].set_ylim(-100000,) axs[0].set_xlim(15,60)  axs[1].set_xlim(15,60) axs[1].set_ylim(0,200000)  axs[2].set_ylim(0,200000) axs[2].set_xlim(10,60) plt.show() <p>There are 5 peaks (5 hydrocarbons) on the middle FID column, on the 'long' FID columns the compounds are not separated. On the TCD channel, we see a clearly saturated Nitrogen peak, as well as a small hydrogen peak.</p> <p>Next, we define the peaks we want to integrate:</p> In\u00a0[\u00a0]: Copied! <pre>Peaks_FID_L = {\n    'All_FID_L': [15, 18]\n}\nPeaks_FID_M = {\n    'Pentane': [54, 58],\n    'Butane': [34, 38],\n    'Propane': [29, 34],\n    'Ethane': [27.87, 29.26],\n    'Methane': [27.5, 27.87],\n    'ALL_products_FID_M': [26, 150]\n}\n\nPeaks_TCD = {\n    'N2': [20, 26],\n    'H2': [16, 19]\n}\n</pre> Peaks_FID_L = {     'All_FID_L': [15, 18] } Peaks_FID_M = {     'Pentane': [54, 58],     'Butane': [34, 38],     'Propane': [29, 34],     'Ethane': [27.87, 29.26],     'Methane': [27.5, 27.87],     'ALL_products_FID_M': [26, 150] }  Peaks_TCD = {     'N2': [20, 26],     'H2': [16, 19] } <p>Next we integrate each channel:</p> In\u00a0[5]: Copied! <pre>integrals_FID_L = exp_mto.channels['FID_L'].integrate_peaks(peaklist=Peaks_FID_L,).drop(columns=['Timestamp'])\nintegrals_FID_M = exp_mto.channels['FID_M'].integrate_peaks(peaklist=Peaks_FID_M,).drop(columns=['Timestamp'])\nintegrals_TCD = exp_mto.channels['TCD'].integrate_peaks(peaklist=Peaks_TCD,).drop(columns=['Timestamp'])\n\npeak_areas = pd.concat([integrals_FID_L, integrals_FID_M, integrals_TCD], axis=1)\n</pre> integrals_FID_L = exp_mto.channels['FID_L'].integrate_peaks(peaklist=Peaks_FID_L,).drop(columns=['Timestamp']) integrals_FID_M = exp_mto.channels['FID_M'].integrate_peaks(peaklist=Peaks_FID_M,).drop(columns=['Timestamp']) integrals_TCD = exp_mto.channels['TCD'].integrate_peaks(peaklist=Peaks_TCD,).drop(columns=['Timestamp'])  peak_areas = pd.concat([integrals_FID_L, integrals_FID_M, integrals_TCD], axis=1) <p>We do a quick plot to see if some injections deviate significantly from the rest.</p> In\u00a0[6]: Copied! <pre>Fig, axs = plt.subplots(3,1, figsize=(7,7/1.618))\naxs[0].plot(peak_areas.index, peak_areas['All_FID_L']/peak_areas['All_FID_L'].max()*100, 'o-')\naxs[0].axhline(peak_areas['All_FID_L'].mean()/peak_areas['All_FID_L'].max()*100, color='r', linestyle='--')\n\naxs[1].plot(peak_areas.index, peak_areas['ALL_products_FID_M']/peak_areas['ALL_products_FID_M'].max()*100, 'o-')\naxs[1].axhline(peak_areas['ALL_products_FID_M'].mean()/peak_areas['ALL_products_FID_M'].max()*100, color='r', linestyle='--')\n\naxs[2].plot(peak_areas.index, peak_areas['H2']/peak_areas['H2'].max()*100, 'o-')\naxs[2].axhline(peak_areas['H2'].mean()/peak_areas['H2'].max()*100, color='r', linestyle='--')\n\n\nfor ax in axs:\n    ax.set_ylim(90,110)\nplt.tight_layout()\nplt.show()\n</pre> Fig, axs = plt.subplots(3,1, figsize=(7,7/1.618)) axs[0].plot(peak_areas.index, peak_areas['All_FID_L']/peak_areas['All_FID_L'].max()*100, 'o-') axs[0].axhline(peak_areas['All_FID_L'].mean()/peak_areas['All_FID_L'].max()*100, color='r', linestyle='--')  axs[1].plot(peak_areas.index, peak_areas['ALL_products_FID_M']/peak_areas['ALL_products_FID_M'].max()*100, 'o-') axs[1].axhline(peak_areas['ALL_products_FID_M'].mean()/peak_areas['ALL_products_FID_M'].max()*100, color='r', linestyle='--')  axs[2].plot(peak_areas.index, peak_areas['H2']/peak_areas['H2'].max()*100, 'o-') axs[2].axhline(peak_areas['H2'].mean()/peak_areas['H2'].max()*100, color='r', linestyle='--')   for ax in axs:     ax.set_ylim(90,110) plt.tight_layout() plt.show() <p>We throw out the first two and look at the mean and standard deviation. If the errors are too large, it could be an issue with the baseline, the peak boundaries, or the measurement itself. In our case, the larger deviation for the methane peak is likely due to the poor separation from the ethane peak. For the other peaks, we have deviations significantly below 1%.</p> In\u00a0[7]: Copied! <pre>peak_areas_red = peak_areas.iloc[2:] \n# check mean, std and the relative std\n\nresults = peak_areas_red.describe(include='all').T[['mean','std']]\nresults['rel_std(%)'] = results['std']/results['mean']*100\nresults = results.sort_values('rel_std(%)')\nprint(results)\n</pre> peak_areas_red = peak_areas.iloc[2:]  # check mean, std and the relative std  results = peak_areas_red.describe(include='all').T[['mean','std']] results['rel_std(%)'] = results['std']/results['mean']*100 results = results.sort_values('rel_std(%)') print(results) <pre>                            mean           std  rel_std(%)\nN2                  1.974884e+07  13188.784646    0.066783\nAll_FID_L           3.357269e+06   2514.523884    0.074898\nPentane             6.163667e+04     97.134246    0.157592\nButane              2.726687e+05    434.329830    0.159288\nPropane             6.391794e+05   1026.447373    0.160588\nALL_products_FID_M  1.045433e+06   1848.405804    0.176808\nEthane              4.610635e+04    221.736694    0.480924\nH2                  1.009140e+04    409.497726    4.057888\nMethane             1.500512e+04   1616.426102   10.772500\n</pre> <p>The concentrations of our calibration bottle are determined in vol%. To get a single-point calibration factor for each species, we divide the peak area by the concentration:</p> <p>\\begin{equation} \tCF_{vol\\%} = \\dfrac{A_{peak}}{c_{vol\\%}}  \\end{equation}</p> <p>Depending on the unit you need, you can first convert vol% into the unit you need. For this you can use e.g. the ideal gas law, just keep in mind its limitations.</p> In\u00a0[8]: Copied! <pre>bottle_content = pd.DataFrame(columns=['vol_pct'],index=['Pentane','Butane','Propane','Ethane','Methane'])\nbottle_content['vol_pct'] = [0.535,2.97,9.16,0.971,1.003]\nbottle_content['C_atoms'] = [5,4,3,2,1]\n# for the middle channel\nCF_mid = {component: (results['mean'].loc[component]/bottle_content['vol_pct'][component]) for component in bottle_content.index}\nprint(CF_mid)\n</pre> bottle_content = pd.DataFrame(columns=['vol_pct'],index=['Pentane','Butane','Propane','Ethane','Methane']) bottle_content['vol_pct'] = [0.535,2.97,9.16,0.971,1.003] bottle_content['C_atoms'] = [5,4,3,2,1] # for the middle channel CF_mid = {component: (results['mean'].loc[component]/bottle_content['vol_pct'][component]) for component in bottle_content.index} print(CF_mid) <pre>{'Pentane': np.float64(115208.73239780453), 'Butane': np.float64(91807.6364532858), 'Propane': np.float64(69779.41050035295), 'Ethane': np.float64(47483.37169203404), 'Methane': np.float64(14960.23518124579)}\n</pre> <p>Dividing the peak area by the calibration factor above will return the concentration in vol%. We can check how much the FID response changes between the molecules by accounting for the carbon number:</p> In\u00a0[9]: Copied! <pre>CF_per_C_atom = {component: ((results['mean'].loc[component]/bottle_content['C_atoms'][component])/bottle_content['vol_pct'][component]) for component in bottle_content.index}\n\ncf_per_c_atom_df = pd.DataFrame.from_dict(CF_per_C_atom, orient='index', columns=['CF_per_C_atom'])\nprint(cf_per_c_atom_df)\n</pre> CF_per_C_atom = {component: ((results['mean'].loc[component]/bottle_content['C_atoms'][component])/bottle_content['vol_pct'][component]) for component in bottle_content.index}  cf_per_c_atom_df = pd.DataFrame.from_dict(CF_per_C_atom, orient='index', columns=['CF_per_C_atom']) print(cf_per_c_atom_df) <pre>         CF_per_C_atom\nPentane   23041.746480\nButane    22951.909113\nPropane   23259.803500\nEthane    23741.685846\nMethane   14960.235181\n</pre> <p>As you can see the FID response per carbon atom is largely similar, with the exception of methane.</p> <p>But what if you want to analyze a compound for which you don't have a calibration mixture? In this case you can make an estimation of the concentration from the other compounds. In my particular use case, I wanted to get the partial pressure of 2-4 dimethyl-pentane specifically from the FID_L channel. One approach would be to determine the CF depending on the carbon number, and then extrapolate to the 7 carbon atoms of my molecule. However, as you could see in the chromatograms above, we can't really separate the compounds on this channel.</p> <p>To still be able to get an estimation of the partial pressure, we simply determine the total concentration of carbon atoms in the gas mixture as follows:</p> <ul> <li>we assume the ideal gas law holds, i.e. the vol% proportional to n%, i.e.</li> <li>The signal is perfectly proportional to the carbon number</li> </ul> In\u00a0[10]: Copied! <pre># We determine the molar concentartion (dividing by 100) and then get the number of carbon atoms by multiplying with the carbon number\nbottle_content['n(molecule)*CN'] = bottle_content['vol_pct']/100*bottle_content['C_atoms']\n# the total concentartion of carbon atoms in the gas mixture\nsum_n_CN = bottle_content['n(molecule)*CN'].sum()\n# Getting the calibration factor per carbon atom by dividing the total signal by the total concentration\nCF_CN = results.loc['All_FID_L','mean'] / sum_n_CN\n\nprint(f\"Calibration factor per carbon atom: {CF_CN} \")\n</pre> # We determine the molar concentartion (dividing by 100) and then get the number of carbon atoms by multiplying with the carbon number bottle_content['n(molecule)*CN'] = bottle_content['vol_pct']/100*bottle_content['C_atoms'] # the total concentartion of carbon atoms in the gas mixture sum_n_CN = bottle_content['n(molecule)*CN'].sum() # Getting the calibration factor per carbon atom by dividing the total signal by the total concentration CF_CN = results.loc['All_FID_L','mean'] / sum_n_CN  print(f\"Calibration factor per carbon atom: {CF_CN} \") <pre>Calibration factor per carbon atom: 7463915.174603943 \n</pre> <p>When the peak area is divided by this calibration factor, and then divided by the number of carbon atoms in the molecule, the vol % is obtained</p> <p>\\begin{equation} \tc_{vol\\%} = \\dfrac{A_{peak}}{CF_{CN} \\cdot CN} \\end{equation}</p> <p>Where CN is the carbon number of the molecule.</p> <p>Calibration of the pyGCMS is more complicated as the system uses sample loops (15 of them). We load the gas mixture into all loops, and inject them one by one onto the system. The procedure is repeated 3 times, to calibrate each loop individually. We therefore have 3 directories (for 3 separate runs) containing the data.</p> In\u00a0[11]: Copied! <pre>data_home = Path(\"../..\")/\"dev_data\" / \"chroms\" /  \"pyGCMS_calibration\"\ndirs = sorted((data_home).iterdir())\n\nfrom chromstream.data_processing import min_subtract\nruns = []\n\nfor i, dir in enumerate(dirs):\n    run= Experiment(f\"pyGCMS_calib_run{i}\")\n    for chrom_path in sorted(dir.iterdir()):\n        chrom = csp.parse_chromatogram_txt(chrom_path)\n        # subtract the minimum as a baseline to start with\n        chrom.apply_baseline(min_subtract, inplace=True)\n        # adding the chromatogram to the experiment\n        run.add_chromatogram(chrom)\n    runs.append(run)\n    \n</pre> data_home = Path(\"../..\")/\"dev_data\" / \"chroms\" /  \"pyGCMS_calibration\" dirs = sorted((data_home).iterdir())  from chromstream.data_processing import min_subtract runs = []  for i, dir in enumerate(dirs):     run= Experiment(f\"pyGCMS_calib_run{i}\")     for chrom_path in sorted(dir.iterdir()):         chrom = csp.parse_chromatogram_txt(chrom_path)         # subtract the minimum as a baseline to start with         chrom.apply_baseline(min_subtract, inplace=True)         # adding the chromatogram to the experiment         run.add_chromatogram(chrom)     runs.append(run)       In\u00a0[12]: Copied! <pre>%matplotlib widget\nruns[2].plot_chromatograms()\n</pre> %matplotlib widget runs[2].plot_chromatograms()                      Figure                  <p>We start by integrating the FID channel for each experiment within specified bounds, then combining all results into one dataframe.</p> In\u00a0[13]: Copied! <pre>Peaks = {'Methane_Ethane':[1.93,1.99], \n        'Propane':[1.99,2.04],\n        'Butane': [2.085,2.16],\n        'Pentane':[2.325,2.385]}\nintegral_list = []\nfor i,exp in enumerate(runs):\n    integrals = exp.channels['FID_right'].integrate_peaks(peaklist=Peaks)\n    integrals = integrals.sort_values('Timestamp').reset_index(drop=True)\n    integrals['Loop'] = integrals.index + 1\n    integrals['run'] = i+1\n    #We drop the first row as it does not work properly\n    integrals = integrals.drop(index=0)\n    integral_list.append(integrals)\n\nall_integrals = pd.concat(integral_list).reset_index(drop=True)\n</pre> Peaks = {'Methane_Ethane':[1.93,1.99],          'Propane':[1.99,2.04],         'Butane': [2.085,2.16],         'Pentane':[2.325,2.385]} integral_list = [] for i,exp in enumerate(runs):     integrals = exp.channels['FID_right'].integrate_peaks(peaklist=Peaks)     integrals = integrals.sort_values('Timestamp').reset_index(drop=True)     integrals['Loop'] = integrals.index + 1     integrals['run'] = i+1     #We drop the first row as it does not work properly     integrals = integrals.drop(index=0)     integral_list.append(integrals)  all_integrals = pd.concat(integral_list).reset_index(drop=True) <p>Next we determine the mean and std deviation for each loop across the three runs</p> In\u00a0[14]: Copied! <pre>integrals_mean = all_integrals.groupby('Loop').mean().drop(columns=['run','Timestamp'])\nintegrals_std = all_integrals.groupby('Loop').std().drop(columns=['run','Timestamp'])\nintegrals_results_relative = integrals_std/integrals_mean*100\n# if there is an entry &gt;1, raise a warning\nif (integrals_results_relative&gt;1).any().any():\n    print(\"Warning: Relative std. dev &gt; 1% detected\")\n    \nintegrals_results_relative.plot(xlabel='Loop', ylabel='Relative std (%)')\n</pre> integrals_mean = all_integrals.groupby('Loop').mean().drop(columns=['run','Timestamp']) integrals_std = all_integrals.groupby('Loop').std().drop(columns=['run','Timestamp']) integrals_results_relative = integrals_std/integrals_mean*100 # if there is an entry &gt;1, raise a warning if (integrals_results_relative&gt;1).any().any():     print(\"Warning: Relative std. dev &gt; 1% detected\")      integrals_results_relative.plot(xlabel='Loop', ylabel='Relative std (%)') Out[14]: <pre>&lt;Axes: xlabel='Loop', ylabel='Relative std (%)'&gt;</pre>                      Figure                  <p>As you can see the standard deviation is below 1%. Next, we determine the calibration factors for each compound by dividing the known concentration by the area. Since we cannot discern between methane and ethane on this channel, we will only utilize propane-pentane for the consecutive analysis.</p> In\u00a0[15]: Copied! <pre>bottle_content = pd.DataFrame(columns=['vol_pct'],\n                              index=['Pentane','Butane','Propane','Ethane','Methane'])\nbottle_content['vol_pct'] = [0.535,2.97,9.16,0.971,1.003]\nbottle_content['C_atoms'] = [5,4,3,2,1]\n\nCF_vol = pd.DataFrame() # this now contains the calibration factor in units of peak_area/vol_pct\nfor compounds in ['Pentane','Butane','Propane']:\n    CF_vol[compounds] = integrals_mean[compounds]/bottle_content['vol_pct'][compounds]\n</pre> bottle_content = pd.DataFrame(columns=['vol_pct'],                               index=['Pentane','Butane','Propane','Ethane','Methane']) bottle_content['vol_pct'] = [0.535,2.97,9.16,0.971,1.003] bottle_content['C_atoms'] = [5,4,3,2,1]  CF_vol = pd.DataFrame() # this now contains the calibration factor in units of peak_area/vol_pct for compounds in ['Pentane','Butane','Propane']:     CF_vol[compounds] = integrals_mean[compounds]/bottle_content['vol_pct'][compounds]  <p>To make this analysis more general,we determine a calibration factor normalized to the carbon number. For this we conduct a linear regression for each loop, using the carbon number as x-axis and the CF as y axis:</p> In\u00a0[16]: Copied! <pre>from scipy import stats\nCF_corrected = {}\nCarbon_numbers = {'Pentane':5, 'Butane':4, 'Propane':3}\nfor loop in CF_vol.index:\n    slope, intercept, r_value, p_value, std_err = stats.linregress(list(Carbon_numbers.values()), CF_vol.loc[loop, list(Carbon_numbers.keys())])\n    # when there is a clear outlier, raise a warning\n    if r_value &lt; 0.99:\n        print(f\"Warning: r_value for loop {loop} is {r_value}, which is below 0.99\")\n    CF_corrected[loop] = slope  #slope is the calibration factor per carbon atom\n\nresults = pd.DataFrame.from_dict(CF_corrected, orient='index', columns=['CF_per_C_atom'])\nresults.index.name = 'Loop'\nresults.head()\n</pre> from scipy import stats CF_corrected = {} Carbon_numbers = {'Pentane':5, 'Butane':4, 'Propane':3} for loop in CF_vol.index:     slope, intercept, r_value, p_value, std_err = stats.linregress(list(Carbon_numbers.values()), CF_vol.loc[loop, list(Carbon_numbers.keys())])     # when there is a clear outlier, raise a warning     if r_value &lt; 0.99:         print(f\"Warning: r_value for loop {loop} is {r_value}, which is below 0.99\")     CF_corrected[loop] = slope  #slope is the calibration factor per carbon atom  results = pd.DataFrame.from_dict(CF_corrected, orient='index', columns=['CF_per_C_atom']) results.index.name = 'Loop' results.head() Out[16]: CF_per_C_atom Loop 2 3.649613 3 4.010493 4 4.065350 5 4.065766 6 4.067702 In\u00a0[17]: Copied! <pre>from chromstream.data_processing import time_point_baseline\n\n\nPeaks = {'Nitrogen':[12.7,14.8],'Hydrogen': [10.9,11.3], 'Propane': [7.8,9]}\nbaseline_points = {'Nitrogen': 12.5, 'Hydrogen': 10.9, 'Propane': [7.7]}\nintegral_list = []\nfor i,exp in enumerate(runs):\n    integral_peak = {}\n    for peak in Peaks:\n        # apply the point baseline to a channel\n        exp.channels['TCD'].apply_baseline(\n            time_point_baseline,\n            time_point=baseline_points[peak],\n            inplace=True,\n            suffix=f\"_BL_t{baseline_points[peak]}\")\n        \n        integrals = exp.channels['TCD'].integrate_peaks({peak: Peaks[peak]})\n        integral_peak[peak] = integrals\n\n    integrals = pd.concat(integral_peak.values(), axis=1)\n    integrals = integrals.loc[:,~integrals.columns.duplicated()]#drop duplicate Timestamp columns\n    integrals = integrals.sort_values('Timestamp').reset_index(drop=True)\n    integrals['Loop'] = integrals.index + 1\n    integrals['run'] = i+1\n    \n    #We drop the first row as it does not work properly\n    integrals = integrals.drop(index=0)\n    integral_list.append(integrals)\n\nall_integrals = pd.concat(integral_list).reset_index(drop=True)\nall_integrals.head()\n</pre> from chromstream.data_processing import time_point_baseline   Peaks = {'Nitrogen':[12.7,14.8],'Hydrogen': [10.9,11.3], 'Propane': [7.8,9]} baseline_points = {'Nitrogen': 12.5, 'Hydrogen': 10.9, 'Propane': [7.7]} integral_list = [] for i,exp in enumerate(runs):     integral_peak = {}     for peak in Peaks:         # apply the point baseline to a channel         exp.channels['TCD'].apply_baseline(             time_point_baseline,             time_point=baseline_points[peak],             inplace=True,             suffix=f\"_BL_t{baseline_points[peak]}\")                  integrals = exp.channels['TCD'].integrate_peaks({peak: Peaks[peak]})         integral_peak[peak] = integrals      integrals = pd.concat(integral_peak.values(), axis=1)     integrals = integrals.loc[:,~integrals.columns.duplicated()]#drop duplicate Timestamp columns     integrals = integrals.sort_values('Timestamp').reset_index(drop=True)     integrals['Loop'] = integrals.index + 1     integrals['run'] = i+1          #We drop the first row as it does not work properly     integrals = integrals.drop(index=0)     integral_list.append(integrals)  all_integrals = pd.concat(integral_list).reset_index(drop=True) all_integrals.head() Out[17]: Timestamp Nitrogen Hydrogen Propane Loop run 0 2025-01-14 14:09:55 22.920375 0.006642 2.757142 2 1 1 2025-01-14 14:41:08 24.835361 0.007078 3.030840 3 1 2 2025-01-14 15:11:33 24.977383 0.006926 3.055321 4 1 3 2025-01-14 15:41:56 24.929261 0.007205 3.050116 5 1 4 2025-01-14 16:12:20 24.990309 0.007169 3.058718 6 1 In\u00a0[18]: Copied! <pre>integrals_mean = all_integrals.groupby('Loop').mean().drop(columns=['run','Timestamp'])\nintegrals_std = all_integrals.groupby('Loop').std().drop(columns=['run','Timestamp'])\nintegrals_results_relative = integrals_std/integrals_mean*100\n# if there is an entry &gt;1, raise a warning\nif (integrals_results_relative&gt;1).any().any():\n    print(\"Warning: Relative std. dev &gt; 1% detected\")\n    \nintegrals_results_relative.plot(xlabel='Loop', ylabel='Relative std (%)')\n</pre> integrals_mean = all_integrals.groupby('Loop').mean().drop(columns=['run','Timestamp']) integrals_std = all_integrals.groupby('Loop').std().drop(columns=['run','Timestamp']) integrals_results_relative = integrals_std/integrals_mean*100 # if there is an entry &gt;1, raise a warning if (integrals_results_relative&gt;1).any().any():     print(\"Warning: Relative std. dev &gt; 1% detected\")      integrals_results_relative.plot(xlabel='Loop', ylabel='Relative std (%)') <pre>Warning: Relative std. dev &gt; 1% detected\n</pre> Out[18]: <pre>&lt;Axes: xlabel='Loop', ylabel='Relative std (%)'&gt;</pre>                      Figure                  <p>The standard dev for hydrogen is rather high, might need to tune the integration</p> In\u00a0[19]: Copied! <pre>bottle_content = pd.DataFrame(columns=['vol_pct'],index=['Nitrogen','Hydrogen','Propane'])\nbottle_content['vol_pct'] = [84.356, 1.005, 9.16]\n\n\nCF_vol = pd.DataFrame() # this now contains the calibration factor in units of peak_area/vol_pct\nfor compounds in ['Nitrogen','Hydrogen','Propane']:\n    CF_vol[compounds] = integrals_mean[compounds]/bottle_content['vol_pct'][compounds]\n\nCF_vol.head()\n</pre> bottle_content = pd.DataFrame(columns=['vol_pct'],index=['Nitrogen','Hydrogen','Propane']) bottle_content['vol_pct'] = [84.356, 1.005, 9.16]   CF_vol = pd.DataFrame() # this now contains the calibration factor in units of peak_area/vol_pct for compounds in ['Nitrogen','Hydrogen','Propane']:     CF_vol[compounds] = integrals_mean[compounds]/bottle_content['vol_pct'][compounds]  CF_vol.head() Out[19]: Nitrogen Hydrogen Propane Loop 2 0.271879 0.006178 0.304144 3 0.295574 0.007140 0.332513 4 0.296890 0.006903 0.334392 5 0.296229 0.007274 0.333739 6 0.296760 0.007343 0.334424"},{"location":"notebooks/example_calibration.html#online-gc-calibration","title":"Online GC Calibration\u00b6","text":"<p>The purpose of calibrating an on-line GC is to obtain quantitative concentration data of a gas stream. In order to do so, a calibration gas (mixture) is injected onto the GC. This allows to obtain a relationship between the peak area and the concentration in the calibration bottle. Note that when calibrating a 'conventional' GC, samples with different concentrations are injected, allowing to establish a proper response factor. Since here generally only one bottle is used, we are effectively doing single-point calibrations, and often rely on a plethora of other assumptions. What we are doing is not 'fine analytic chemistry'. The most important reason to calibrate is to account for drift in the detectors between experiments over longer periods of time. I have seen differences of 10% between calibrations a year apart, so take this into consideration when comparing experiments. Another important factor is to use the same pressure in your calibration as your experiment, or account for the difference when analyzing the data. More carbon in the injection loop = more signal.</p> <p>Below I will provide examples for the calibration of two different GC systems:</p> <ul> <li>Conventional on-line GC system</li> <li>GC System with heated sample loops</li> </ul>"},{"location":"notebooks/example_calibration.html#mto-setup","title":"MTO setup\u00b6","text":""},{"location":"notebooks/example_calibration.html#pygcms","title":"pyGCMS\u00b6","text":""},{"location":"notebooks/example_calibration.html#fid-channel","title":"FID Channel\u00b6","text":""},{"location":"notebooks/example_calibration.html#tcd-channel","title":"TCD Channel\u00b6","text":"<p>For the TCD channel we have the complication that we don't really have a stable baseline. This means that we need to specify a baseline for each peak.</p>"},{"location":"notebooks/splitting_examples.html","title":"MTO setup","text":"In\u00a0[1]: Copied! <pre>from chromstream.parsers import parse_chromatogram_txt\nfrom chromstream.objects import Chromatogram\nfrom chromstream.objects import Experiment\nimport os\nfrom pathlib import Path\n\nimport re\nimport pandas as pd\nimport logging as log\n</pre> from chromstream.parsers import parse_chromatogram_txt from chromstream.objects import Chromatogram from chromstream.objects import Experiment import os from pathlib import Path  import re import pandas as pd import logging as log  In\u00a0[2]: Copied! <pre>exp2 = Experiment(name=\"Bas\")\ndata_home = Path(\"..\") / \"dev_data\" / \"chroms\" /  \"small_GC_ballmill\" / \"Ina\"\npaths_all = sorted((data_home).iterdir())\n# adding chromatograms\n\nfrom chromstream.data_processing import min_subtract, time_window_baseline, split_chromatogram\n\nfor p in paths_all:\n    chrom = parse_chromatogram_txt(p)\n    chrom.apply_baseline(min_subtract, inplace=False)\n    exp2.add_chromatogram(chrom)\n# adding log files\n</pre> exp2 = Experiment(name=\"Bas\") data_home = Path(\"..\") / \"dev_data\" / \"chroms\" /  \"small_GC_ballmill\" / \"Ina\" paths_all = sorted((data_home).iterdir()) # adding chromatograms  from chromstream.data_processing import min_subtract, time_window_baseline, split_chromatogram  for p in paths_all:     chrom = parse_chromatogram_txt(p)     chrom.apply_baseline(min_subtract, inplace=False)     exp2.add_chromatogram(chrom) # adding log files <p>Attempts at a splitting function</p> In\u00a0[8]: Copied! <pre>chromatogram = exp2.channels['TCD_Ch_4'].chromatograms[0]\n# chromatogram = exp2.channels['FID_Ch1'].chromatograms[51]\nsplit_chromatograms = split_chromatogram(chromatogram, 4,start_offset=300, end_offset=0, reset_time=True)\n\n\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nfor chrom in split_chromatograms:\n    # print(chrom.data['Value (pA)'].idxmax())\n    # print(len(chrom.data))\n    chrom.plot(ax=ax, label=chrom.injection_time.strftime(\"%H:%M:%S\"))\nax.legend()\n# ax.axvline(1.16)\n</pre> chromatogram = exp2.channels['TCD_Ch_4'].chromatograms[0] # chromatogram = exp2.channels['FID_Ch1'].chromatograms[51] split_chromatograms = split_chromatogram(chromatogram, 4,start_offset=300, end_offset=0, reset_time=True)   import matplotlib.pyplot as plt fig, ax = plt.subplots() for chrom in split_chromatograms:     # print(chrom.data['Value (pA)'].idxmax())     # print(len(chrom.data))     chrom.plot(ax=ax, label=chrom.injection_time.strftime(\"%H:%M:%S\")) ax.legend() # ax.axvline(1.16) Out[8]: <pre>&lt;matplotlib.legend.Legend at 0x7fae4b188ad0&gt;</pre> In\u00a0[5]: Copied! <pre>data_home_logs = Path(\"..\") / \"dev_data\" /\"logs\"/ \"Nicolette\" \npaths_logs = sorted((data_home_logs).iterdir())\n\nexp3 = Experiment(name=\"Nicolette\")\ndata_home = Path(\"..\") / \"dev_data\" / \"chroms\" /  \"Nicolette\" \npaths_all = sorted((data_home).iterdir())\n# adding chromatograms\n\n\nfor p in paths_all:\n    chrom = parse_chromatogram_txt(p)\n    chrom.apply_baseline(min_subtract, inplace=False)\n    exp3.add_chromatogram(chrom)\n</pre> data_home_logs = Path(\"..\") / \"dev_data\" /\"logs\"/ \"Nicolette\"  paths_logs = sorted((data_home_logs).iterdir())  exp3 = Experiment(name=\"Nicolette\") data_home = Path(\"..\") / \"dev_data\" / \"chroms\" /  \"Nicolette\"  paths_all = sorted((data_home).iterdir()) # adding chromatograms   for p in paths_all:     chrom = parse_chromatogram_txt(p)     chrom.apply_baseline(min_subtract, inplace=False)     exp3.add_chromatogram(chrom) In\u00a0[6]: Copied! <pre># chromatogram = exp2.channels['TCD_Ch2_3'].chromatograms[51]\nchromatogram = exp3.channels['FID_Ch1'].chromatograms[51]\nsplit_chromatograms = split_chromatogram(chromatogram, 6,start_offset=0, end_offset=0, reset_time=False)\nfig, ax = plt.subplots()\nfor chrom in split_chromatograms:\n    chrom.plot(ax=ax, label=chrom.injection_time.strftime(\"%H:%M:%S\"))\n    print(len(chrom.data))\nax.legend()\n</pre> # chromatogram = exp2.channels['TCD_Ch2_3'].chromatograms[51] chromatogram = exp3.channels['FID_Ch1'].chromatograms[51] split_chromatograms = split_chromatogram(chromatogram, 6,start_offset=0, end_offset=0, reset_time=False) fig, ax = plt.subplots() for chrom in split_chromatograms:     chrom.plot(ax=ax, label=chrom.injection_time.strftime(\"%H:%M:%S\"))     print(len(chrom.data)) ax.legend() <pre>7000\n7000\n7000\n7000\n7000\n7000\n</pre> Out[6]: <pre>&lt;matplotlib.legend.Legend at 0x7fae4b3b1150&gt;</pre>"},{"location":"notebooks/splitting_examples.html#mto-setup","title":"MTO setup\u00b6","text":""},{"location":"notebooks/splitting_examples.html#logfile-parsers","title":"Logfile parsers\u00b6","text":""},{"location":"reference/SUMMARY.html","title":"SUMMARY","text":"<ul> <li>chromstream<ul> <li>data_processing</li> <li>objects</li> <li>parsers</li> </ul> </li> </ul>"},{"location":"reference/chromstream/data_processing.html","title":"data_processing","text":"<p>Data processing functions for chromatogram analysis</p>"},{"location":"reference/chromstream/data_processing.html#chromstream.data_processing.add_log_data","title":"add_log_data","text":"<pre><code>add_log_data(Integral_Frame: DataFrame, Log: DataFrame, columns: list[str] | all = 'all') -&gt; DataFrame\n</code></pre> <p>For a dataframe that contains a timestamp column, data from a log dataframe is added.  The log dataframe must similarly contain a timestamp column.  Args:      Integral_Frame (pd.DataFrame): DataFrame containing e.g. chromatogram integrals.      Log (pd.DataFrame): DataFrame containing log data with a timestamp column.      columns (list[str] | 'all', optional): List of columns from the log to add. If 'all', all columns except timestamp are added. Defaults to 'all'.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: DataFrame containing the original dataframe data with log data added.</p> </li> </ul> Source code in <code>chromstream/data_processing.py</code> <pre><code>def add_log_data(\n    Integral_Frame: pd.DataFrame, Log: pd.DataFrame, columns: list[str] | all = \"all\"\n) -&gt; pd.DataFrame:\n    \"\"\"\n     For a dataframe that contains a timestamp column, data from a log dataframe is added.\n     The log dataframe must similarly contain a timestamp column.\n     Args:\n         Integral_Frame (pd.DataFrame): DataFrame containing e.g. chromatogram integrals.\n         Log (pd.DataFrame): DataFrame containing log data with a timestamp column.\n         columns (list[str] | 'all', optional): List of columns from the log to add. If 'all', all columns except timestamp are added. Defaults to 'all'.\n\n    Returns:\n        pd.DataFrame: DataFrame containing the original dataframe data with log data added.\n    \"\"\"\n\n    # Data validation\n    if \"Timestamp\" not in Integral_Frame.columns:\n        raise ValueError(\"Integral_Frame must contain a 'Timestamp' column.\")\n    if \"Timestamp\" not in Log.columns:\n        raise ValueError(\"Log must contain a 'Timestamp' column.\")\n\n    # check if the first timestamp of the log is after the first timestamp of the integral frame\n    if Log[\"Timestamp\"].min() &gt; Integral_Frame[\"Timestamp\"].max():\n        raise ValueError(\n            \"The first timestamp of the log is after the last timestamp of the \"\n            \"Integral_Frame. Check whether the right files are selected.\"\n        )\n\n    if Log[\"Timestamp\"].max() &lt; Integral_Frame[\"Timestamp\"].min():\n        raise ValueError(\n            \"The last timestamp of the log is before the first timestamp of the \"\n            \"Integral_Frame. Check whether the right files are selected.\"\n        )\n    # Ensuring dfs are sorted by timestamp\n    Integral_Frame = Integral_Frame.sort_values(\"Timestamp\")\n    Log = Log.sort_values(\"Timestamp\")\n\n    if columns == \"all\":\n        # If 'all', add all columns except timestamp\n        columns = [col for col in Log.columns if col != \"Timestamp\"]\n    elif not isinstance(columns, list):\n        raise ValueError(\"columns must be a list of column names or 'all'.\")\n\n    # Merging the dataframes\n    merged = pd.merge_asof(\n        Integral_Frame,\n        Log[[\"Timestamp\"] + columns],\n        on=\"Timestamp\",\n        direction=\"nearest\",\n    )\n\n    return merged\n</code></pre>"},{"location":"reference/chromstream/data_processing.html#chromstream.data_processing.get_temp_and_valves_MTO","title":"get_temp_and_valves_MTO","text":"<pre><code>get_temp_and_valves_MTO(Integral_Frame, Log)\n</code></pre> <p>For a Dataframe containing chromatogram integrals and a timestamp column, add data from a log file.</p> Source code in <code>chromstream/data_processing.py</code> <pre><code>def get_temp_and_valves_MTO(Integral_Frame, Log):\n    \"\"\"\n    For a Dataframe containing chromatogram integrals and a timestamp column,\n    add data from a log file.\n    \"\"\"\n    integral_copy = Integral_Frame.copy()\n\n    if \"Timestamp\" not in integral_copy.columns:\n        integral_copy = integral_copy.reset_index().rename(\n            columns={\"index\": \"Timestamp\"}\n        )\n\n    # Ensure both DataFrames are sorted by timestamp\n    integral_copy = integral_copy.sort_values(\"Timestamp\")\n    Log = Log.sort_values(\"Timestamp\")\n\n    # Merge to get all log data at once\n    result = pd.merge_asof(\n        integral_copy,\n        Log[[\"Timestamp\", \"Oven Temperature\", \"v10-bubbler\", \"v11-reactor\"]],\n        left_on=\"Timestamp\",\n        right_on=\"Timestamp\",\n        direction=\"nearest\",\n    )\n\n    # Set timestamp as index and return\n    return result.set_index(\"Timestamp\")\n</code></pre>"},{"location":"reference/chromstream/data_processing.html#chromstream.data_processing.integrate_channel","title":"integrate_channel","text":"<pre><code>integrate_channel(chromatogram: ChannelChromatograms, peaklist: dict, column: None | str = None) -&gt; DataFrame\n</code></pre> <p>Integrate the signal of a chromatogram over time.</p> <p>Parameters:</p> <ul> <li> <code>chromatogram</code>               (<code>ChannelChromatograms</code>)           \u2013            <p>ChannelChromatograms object containing the chromatograms to be analyzed</p> </li> <li> <code>peaklist</code>               (<code>dict</code>)           \u2013            <p>Dictionary defining the peaks to integrate. Example:</p> </li> <li> <code>Peaks_TCD = {\"N2\"</code>           \u2013            <p>[20, 26], \"H2\": [16, 19]}</p> </li> <li> <code>column</code>               (<code>None | str</code>, default:                   <code>None</code> )           \u2013            <p>Optional column name to use for integration. If None, uses second column.</p> </li> </ul> <p>Returns:     DataFrame with integrated peak areas for each injection</p> Source code in <code>chromstream/data_processing.py</code> <pre><code>def integrate_channel(\n    chromatogram: ChannelChromatograms, peaklist: dict, column: None | str = None\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Integrate the signal of a chromatogram over time.\n\n    Args:\n        chromatogram: ChannelChromatograms object containing the chromatograms to be analyzed\n        peaklist: Dictionary defining the peaks to integrate. Example:\n        ```\n        Peaks_TCD = {\"N2\": [20, 26], \"H2\": [16, 19]}\n        ```\n        The list values must be in the same unit as the chromatogram.\n        column: Optional column name to use for integration. If None, uses second column.\n    Returns:\n        DataFrame with integrated peak areas for each injection\n    \"\"\"\n\n    results = []\n\n    for chrom in chromatogram.chromatograms.values():\n        injection_result = integrate_single_chromatogram(chrom, peaklist, column)\n        results.append(injection_result)\n\n    return pd.DataFrame(results)\n</code></pre>"},{"location":"reference/chromstream/data_processing.html#chromstream.data_processing.integrate_single_chromatogram","title":"integrate_single_chromatogram","text":"<pre><code>integrate_single_chromatogram(chromatogram: Chromatogram, peaklist: dict, column: None | str = None) -&gt; dict\n</code></pre> <p>Integrate the signal of a single chromatogram over time.</p> <p>Parameters:</p> <ul> <li> <code>chromatogram</code>               (<code>Chromatogram</code>)           \u2013            <p>Chromatogram object containing the data to be analyzed</p> </li> <li> <code>peaklist</code>               (<code>dict</code>)           \u2013            <p>Dictionary defining the peaks to integrate. Example:</p> </li> <li> <code>Peaks_TCD = {\"N2\"</code>           \u2013            <p>[20, 26], \"H2\": [16, 19]}</p> </li> <li> <code>column</code>               (<code>None | str</code>, default:                   <code>None</code> )           \u2013            <p>Optional column name to use for integration. If None, uses second column.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>Dictionary with integrated peak areas and timestamp</p> </li> </ul> Source code in <code>chromstream/data_processing.py</code> <pre><code>def integrate_single_chromatogram(\n    chromatogram: Chromatogram, peaklist: dict, column: None | str = None\n) -&gt; dict:\n    \"\"\"\n    Integrate the signal of a single chromatogram over time.\n\n    Args:\n        chromatogram: Chromatogram object containing the data to be analyzed\n        peaklist: Dictionary defining the peaks to integrate. Example:\n        ```\n        Peaks_TCD = {\"N2\": [20, 26], \"H2\": [16, 19]}\n        ```\n        The list values must be in the same unit as the chromatogram.\n        column: Optional column name to use for integration. If None, uses second column.\n\n    Returns:\n        Dictionary with integrated peak areas and timestamp\n    \"\"\"\n    data = chromatogram.data\n    time_col = data.columns[0]  # the time column must be the first!\n    # need to implement handling of pd.datetime here\n\n    signal_col = column if column is not None else data.columns[1]\n\n    injection_result = {\"Timestamp\": chromatogram.injection_time}\n\n    for peak_name, (start, end) in peaklist.items():\n        # Create a mask for the time window\n        mask = (data[time_col] &gt;= start) &amp; (data[time_col] &lt;= end)\n\n        area = trapezoid(data.loc[mask, signal_col], data.loc[mask, time_col])\n        injection_result[peak_name] = area\n\n    return injection_result\n</code></pre>"},{"location":"reference/chromstream/data_processing.html#chromstream.data_processing.linear_baseline","title":"linear_baseline","text":"<pre><code>linear_baseline(data: DataFrame, start_time: float, end_time: float) -&gt; Series\n</code></pre> <p>Determines a linear baseline between the signal values at the two specified time points and subtracts it from the signal.</p> <p>Parameters:</p> <ul> <li> <code>data</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing time and signal columns</p> </li> <li> <code>start_time</code>               (<code>float</code>)           \u2013            <p>Time point to define the start of the baseline. Use the same unit as the chromatogram.</p> </li> <li> <code>end_time</code>               (<code>float</code>)           \u2013            <p>Time point to define the end of the baseline. Use the same unit as the chromatogram.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Series</code>           \u2013            <p>Corrected signal as pandas Series</p> </li> </ul> Source code in <code>chromstream/data_processing.py</code> <pre><code>def linear_baseline(\n    data: pd.DataFrame, start_time: float, end_time: float\n) -&gt; pd.Series:\n    \"\"\"\n    Determines a linear baseline between the signal values at the two specified time points and\n    subtracts it from the signal.\n\n    Args:\n        data: DataFrame containing time and signal columns\n        start_time: Time point to define the start of the baseline. Use the same unit as the chromatogram.\n        end_time: Time point to define the end of the baseline. Use the same unit as the chromatogram.\n\n    Returns:\n        Corrected signal as pandas Series\n    \"\"\"\n    time_col = data.columns[0]  # \"Time (min)\"\n    signal_col = data.columns[1]\n\n    # Find the closest data points to the specified times\n    start_diff = (data[time_col] - start_time).abs()\n    end_diff = (data[time_col] - end_time).abs()\n    start_index = start_diff.idxmin()\n    end_index = end_diff.idxmin()\n\n    # Get the signal values at these points\n    start_value = data.loc[start_index, signal_col]\n    end_value = data.loc[end_index, signal_col]\n\n    # Calculate the slope and intercept of the baseline line\n    slope = (end_value - start_value) / (  # type: ignore[operator]\n        data.loc[end_index, time_col] - data.loc[start_index, time_col]\n    )\n    intercept = start_value - slope * data.loc[start_index, time_col]  # type: ignore[operator]\n\n    # Calculate the baseline for each time point\n    baseline = slope * data[time_col] + intercept  # type: ignore[operator]\n\n    return data[signal_col] - baseline\n</code></pre>"},{"location":"reference/chromstream/data_processing.html#chromstream.data_processing.list_baseline_functions","title":"list_baseline_functions","text":"<pre><code>list_baseline_functions()\n</code></pre> Source code in <code>chromstream/data_processing.py</code> <pre><code>def list_baseline_functions():\n    baseline_functions = [\n        \"min_subtract\",\n        \"time_window_baseline\",\n        \"time_point_baseline\",\n        \"linear_baseline\",\n    ]\n    return \"\\n\".join(baseline_functions)\n</code></pre>"},{"location":"reference/chromstream/data_processing.html#chromstream.data_processing.min_subtract","title":"min_subtract","text":"<pre><code>min_subtract(data: DataFrame) -&gt; Series\n</code></pre> <p>Simple minimum subtraction baseline correction</p> <p>Parameters:</p> <ul> <li> <code>data</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing time and signal columns</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Series</code>           \u2013            <p>Corrected signal as pandas Series</p> </li> </ul> Source code in <code>chromstream/data_processing.py</code> <pre><code>def min_subtract(data: pd.DataFrame) -&gt; pd.Series:\n    \"\"\"\n    Simple minimum subtraction baseline correction\n\n    Args:\n        data: DataFrame containing time and signal columns\n\n    Returns:\n        Corrected signal as pandas Series\n    \"\"\"\n    signal = data[data.columns[1]]\n    return signal - signal.min()\n</code></pre>"},{"location":"reference/chromstream/data_processing.html#chromstream.data_processing.split_chromatogram","title":"split_chromatogram","text":"<pre><code>split_chromatogram(chromatogram: Chromatogram, n_injections: int, start_offset: int = 0, end_offset: int = 0, reset_time=True) -&gt; list[Chromatogram]\n</code></pre> <p>When multiple injections are contained in a single chromatogram, this function splits the chromatogram into multiple chromatograms Important constraint is the the length of the chromatogram must be divisible by the number of injections. The injection time of each split chromatogram is adjusted based on the runtime. Note:</p> <p>Parameters:</p> <ul> <li> <code>chromatogram</code>               (<code>Chromatogram</code>)           \u2013            <p>The chromatogram to be split.</p> </li> <li> <code>n_injections</code>               (<code>int</code>)           \u2013            <p>The number of injections to split the chromatogram into.</p> </li> <li> <code>start_offset</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Number of data points to skip at the start of the chromatogram. Defaults to 0.</p> </li> <li> <code>end_offset</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Number of data points to skip at the end of the chromatogram. Defaults to 0.</p> </li> <li> <code>reset_time</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to reset the time column to start from 0 for each split chromatogram. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Chromatogram]</code>           \u2013            <p>list[Chromatogram]: A list of split chromatograms.</p> </li> </ul> Source code in <code>chromstream/data_processing.py</code> <pre><code>def split_chromatogram(\n    chromatogram: Chromatogram,\n    n_injections: int,\n    start_offset: int = 0,\n    end_offset: int = 0,\n    reset_time=True,\n) -&gt; list[Chromatogram]:\n    \"\"\"\n    When multiple injections are contained in a single chromatogram, this function splits the chromatogram into multiple chromatograms\n    Important constraint is the the length of the chromatogram must be divisible by the number of injections.\n    The injection time of each split chromatogram is adjusted based on the runtime.\n    Note:\n\n    Args:\n        chromatogram (Chromatogram): The chromatogram to be split.\n        n_injections (int): The number of injections to split the chromatogram into.\n        start_offset (int, optional): Number of data points to skip at the start of the chromatogram. Defaults to 0.\n        end_offset (int, optional): Number of data points to skip at the end of the chromatogram. Defaults to 0.\n        reset_time (bool, optional): Whether to reset the time column to start from 0 for each split chromatogram. Defaults to True.\n\n    Returns:\n        list[Chromatogram]: A list of split chromatograms.\n    \"\"\"\n    end_index = len(chromatogram.data)\n    chrom = (\n        chromatogram.data.iloc[start_offset : (end_index - end_offset)]\n        .reset_index(drop=True)\n        .copy()\n    )\n\n    # Check if divisible by n_injections\n    if len(chrom) % n_injections != 0:\n        raise ValueError(\n            f\"Cannot split chromatograms, as length is not divisible by {n_injections}. Padding needs to be implemented.\"\n        )\n\n    # Calculate split indices, including the end of the data\n    split_indices = [\n        i * (len(chrom) // n_injections) for i in range(1, n_injections)\n    ] + [len(chrom)]\n\n    split_chromatograms = []\n    last_index = 0\n\n    for indx in split_indices:\n        # Slice the data for the current segment\n        data = chrom.iloc[last_index:indx].reset_index(drop=True).copy()\n        last_index = indx\n\n        # Adjust the time column (must be the first column)\n        if chromatogram.time_unit == \"min\":\n            injection_time = chromatogram.injection_time + pd.Timedelta(\n                minutes=data[data.columns[0]].iloc[0]\n            )\n        elif chromatogram.time_unit == \"s\":\n            injection_time = chromatogram.injection_time + pd.Timedelta(\n                seconds=data[data.columns[0]].iloc[0]\n            )\n        else:\n            raise ValueError(\n                f\"Unknown time unit {chromatogram.time_unit}, cannot split chromatogram.\"\n            )\n\n        if reset_time:\n            # reset the time column to start from 0\n            data[data.columns[0]] = (\n                data[data.columns[0]] - data[data.columns[0]].iloc[0]\n            )\n\n        # Create a new Chromatogram object for the split segment\n        from .objects import Chromatogram\n\n        split_chromatogram = Chromatogram(\n            data=data,\n            injection_time=injection_time,\n            metadata=chromatogram.metadata,\n            channel=chromatogram.channel,\n            path=chromatogram.path,\n        )\n        split_chromatograms.append(split_chromatogram)\n\n    return split_chromatograms\n</code></pre>"},{"location":"reference/chromstream/data_processing.html#chromstream.data_processing.time_point_baseline","title":"time_point_baseline","text":"<pre><code>time_point_baseline(data: DataFrame, time_point: float) -&gt; Series\n</code></pre> <p>Use signal value at a specific time point as baseline</p> <p>Parameters:</p> <ul> <li> <code>data</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing time and signal columns</p> </li> <li> <code>time_point</code>               (<code>float</code>)           \u2013            <p>Time point to use as baseline reference. Use the same unit as the chromatogram.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Series</code>           \u2013            <p>Corrected signal as pandas Series</p> </li> </ul> Source code in <code>chromstream/data_processing.py</code> <pre><code>def time_point_baseline(data: pd.DataFrame, time_point: float) -&gt; pd.Series:\n    \"\"\"\n    Use signal value at a specific time point as baseline\n\n    Args:\n        data: DataFrame containing time and signal columns\n        time_point: Time point to use as baseline reference. Use the same unit as the chromatogram.\n\n    Returns:\n        Corrected signal as pandas Series\n    \"\"\"\n    time_col = data.columns[0]  # \"Time (min)\"\n    signal_col = data.columns[1]\n\n    # Find the closest data point to the specified time\n    time_diff = (data[time_col] - time_point).abs()\n    closest_index = time_diff.idxmin()\n    baseline_value = data.loc[closest_index, signal_col]\n\n    return data[signal_col] - baseline_value  # type: ignore[operator]\n</code></pre>"},{"location":"reference/chromstream/data_processing.html#chromstream.data_processing.time_window_baseline","title":"time_window_baseline","text":"<pre><code>time_window_baseline(data: DataFrame, time_window: tuple[float, float] = (0, 1)) -&gt; Series\n</code></pre> <p>Use mean of signal in a specific time window as baseline</p> <p>Parameters:</p> <ul> <li> <code>data</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing time and signal columns</p> </li> <li> <code>time_window</code>               (<code>tuple[float, float]</code>, default:                   <code>(0, 1)</code> )           \u2013            <p>Tuple specifying the start and end time of the baseline window. Use the same unit as the chromatogram.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Series</code>           \u2013            <p>Corrected signal as pandas Series</p> </li> </ul> Source code in <code>chromstream/data_processing.py</code> <pre><code>def time_window_baseline(\n    data: pd.DataFrame, time_window: tuple[float, float] = (0, 1)\n) -&gt; pd.Series:\n    \"\"\"\n    Use mean of signal in a specific time window as baseline\n\n    Args:\n        data: DataFrame containing time and signal columns\n        time_window: Tuple specifying the start and end time of the baseline window. Use the same unit as the chromatogram.\n\n    Returns:\n        Corrected signal as pandas Series\n    \"\"\"\n    start_time, end_time = time_window\n    time_col = data.columns[0]  # \"Time (min)\"\n    signal_col = data.columns[1]\n\n    # Find data points in the specified time window\n    mask = (data[time_col] &gt;= start_time) &amp; (data[time_col] &lt;= end_time)\n    baseline_value = data.loc[mask, signal_col].mean()\n\n    return data[signal_col] - baseline_value  # type: ignore[operator]\n</code></pre>"},{"location":"reference/chromstream/objects.html","title":"objects","text":""},{"location":"reference/chromstream/objects.html#chromstream.objects.ChannelChromatograms","title":"ChannelChromatograms  <code>dataclass</code>","text":"<pre><code>ChannelChromatograms(channel: str, chromatograms: dict[int, Chromatogram] = dict(), integrals: DataFrame | None = None)\n</code></pre> <p>Contains data of a single channel with multiple chromatograms</p> <p>Parameters:</p> <ul> <li> <code>channel</code>               (<code>str</code>)           \u2013            <p>Name of the channel (e.g., 'FID', 'TCD')</p> </li> <li> <code>chromatograms</code>               (<code>dict[int, Chromatogram]</code>, default:                   <code>dict()</code> )           \u2013            <p>Dictionary mapping chromatogram number to Chromatogram objects</p> </li> <li> <code>integrals</code>               (<code>DataFrame | None</code>, default:                   <code>None</code> )           \u2013            <p>DataFrame containing integrated peak areas for each chromatogram (optional)</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>add_chromatogram</code>             \u2013              <p>Add a chromatogram to the channel</p> </li> <li> <code>plot</code>             \u2013              <p>Plot all chromatograms in the channel</p> </li> <li> <code>integrate_peaks</code>             \u2013              <p>Integrate peaks for all chromatograms in the channel, requieres dict of peak limits</p> </li> </ul>"},{"location":"reference/chromstream/objects.html#chromstream.objects.ChannelChromatograms.channel","title":"channel  <code>instance-attribute</code>","text":"<pre><code>channel: str\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.ChannelChromatograms.chromatograms","title":"chromatograms  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>chromatograms: dict[int, Chromatogram] = field(default_factory=dict)\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.ChannelChromatograms.integrals","title":"integrals  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>integrals: DataFrame | None = None\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.ChannelChromatograms.plot_chromatograms","title":"plot_chromatograms  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>plot_chromatograms = plot\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.ChannelChromatograms.add_chromatogram","title":"add_chromatogram","text":"<pre><code>add_chromatogram(injection_num: int, chromatogram: Chromatogram)\n</code></pre> <p>Add a chromatogram for a specific injection</p> Source code in <code>chromstream/objects.py</code> <pre><code>def add_chromatogram(self, injection_num: int, chromatogram: Chromatogram):\n    \"\"\"Add a chromatogram for a specific injection\"\"\"\n    self.chromatograms[injection_num] = chromatogram\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.ChannelChromatograms.apply_baseline","title":"apply_baseline","text":"<pre><code>apply_baseline(correction_func, inplace=False, suffix='_BLcorr', **kwargs)\n</code></pre> <p>Apply baseline correction to all chromatograms in the channel</p> <p>Parameters:</p> <ul> <li> <code>correction_func</code>           \u2013            <p>Function that takes a pandas DataFrame and returns corrected Series</p> </li> <li> <code>inplace</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, modify the original data. If False, add new column</p> </li> <li> <code>suffix</code>               (<code>str</code>, default:                   <code>'_BLcorr'</code> )           \u2013            <p>Suffix to add to the new column name when inplace=False</p> </li> <li> <code>**kwargs</code>           \u2013            <p>Additional arguments to pass to the correction function</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>          \u2013            <p>Modifies chromatograms in place</p> </li> </ul> Source code in <code>chromstream/objects.py</code> <pre><code>def apply_baseline(\n    self, correction_func, inplace=False, suffix=\"_BLcorr\", **kwargs\n):\n    \"\"\"\n    Apply baseline correction to all chromatograms in the channel\n\n    Args:\n        correction_func: Function that takes a pandas DataFrame and returns corrected Series\n        inplace (bool): If True, modify the original data. If False, add new column\n        suffix (str): Suffix to add to the new column name when inplace=False\n        **kwargs: Additional arguments to pass to the correction function\n\n    Returns:\n        None: Modifies chromatograms in place\n    \"\"\"\n    for chrom in self.chromatograms.values():\n        chrom.apply_baseline(\n            correction_func, inplace=inplace, suffix=suffix, **kwargs\n        )\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.ChannelChromatograms.integrate_peaks","title":"integrate_peaks","text":"<pre><code>integrate_peaks(peaklist: dict, column: None | str = None) -&gt; DataFrame\n</code></pre> <p>Integrate peaks for all chromatograms in the channel</p> <p>Parameters:</p> <ul> <li> <code>peaklist</code>               (<code>dict</code>)           \u2013            <p>Dictionary defining the peaks to integrate. Example:</p> </li> <li> <code>Peaks_TCD = {\"N2\"</code>           \u2013            <p>[20, 26], \"H2\": [16, 19]}</p> </li> <li> <code>column</code>               (<code>None | str</code>, default:                   <code>None</code> )           \u2013            <p>Optional column name to use for integration. If None, uses second column.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>DataFrame with integrated peak areas for each injection</p> </li> </ul> Source code in <code>chromstream/objects.py</code> <pre><code>def integrate_peaks(\n    self, peaklist: dict, column: None | str = None\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Integrate peaks for all chromatograms in the channel\n\n    Args:\n        peaklist: Dictionary defining the peaks to integrate. Example:\n        Peaks_TCD = {\"N2\": [20, 26], \"H2\": [16, 19]}\n\n        The list values must be in the same unit as the chromatogram.\n\n        column: Optional column name to use for integration. If None, uses second column.\n\n    Returns:\n        DataFrame with integrated peak areas for each injection\n    \"\"\"\n    self.integrals = integrate_channel(self, peaklist, column=column)\n    return self.integrals\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.ChannelChromatograms.plot","title":"plot","text":"<pre><code>plot(ax=None, colormap='viridis', plot_colorbar=True, **kwargs)\n</code></pre> <p>Plotting all chromatograms of a channel channel</p> Source code in <code>chromstream/objects.py</code> <pre><code>def plot(self, ax=None, colormap=\"viridis\", plot_colorbar=True, **kwargs):\n    \"\"\"Plotting all chromatograms of a channel channel\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    colormap = plt.get_cmap(colormap)\n    colors = colormap(np.linspace(0, 1, len(self.chromatograms)))\n\n    for inj_num, chrom in self.chromatograms.items():\n        ax.plot(\n            chrom.data[chrom.data.columns[0]],\n            chrom.data[chrom.data.columns[1]],\n            label=f\"Injection {inj_num}\",\n            color=colors[inj_num],\n            **kwargs,\n        )\n\n    # Set labels and title (handle empty channel case)\n    if len(self.chromatograms) &gt; 0:\n        # Use any chromatogram to get column names\n        sample_chrom = next(iter(self.chromatograms.values()))\n        ax.set_xlabel(sample_chrom.data.columns[0])\n        ax.set_ylabel(sample_chrom.data.columns[1])\n    else:\n        ax.set_xlabel(\"Time\")\n        ax.set_ylabel(\"Signal\")\n    ax.set_title(f\"Channel: {self.channel}\")\n    # add colorbar\n    if plot_colorbar:\n        sm = plt.cm.ScalarMappable(\n            norm=Normalize(vmin=0, vmax=len(self.chromatograms) - 1)\n        )\n        sm.set_array([])\n        cbar = plt.colorbar(sm, ax=ax)\n        cbar.set_label(\"Injection Number\")\n\n    return ax\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram","title":"Chromatogram  <code>dataclass</code>","text":"<pre><code>Chromatogram(data: DataFrame, injection_time: Timestamp, metadata: dict, channel: str, path: Path | str)\n</code></pre> <p>Single chromatogram data for one injection on one channel</p>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram.channel","title":"channel  <code>instance-attribute</code>","text":"<pre><code>channel: str\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data: DataFrame\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram.injection_time","title":"injection_time  <code>instance-attribute</code>","text":"<pre><code>injection_time: Timestamp\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: dict\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram.path","title":"path  <code>instance-attribute</code>","text":"<pre><code>path: Path | str\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram.signal_unit","title":"signal_unit  <code>property</code>","text":"<pre><code>signal_unit: str\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram.time_unit","title":"time_unit  <code>property</code>","text":"<pre><code>time_unit: str\n</code></pre> <p>Get the time unit from metadata, default to 'min' if not found</p>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram.apply_baseline","title":"apply_baseline","text":"<pre><code>apply_baseline(correction_func, inplace=False, suffix='_BLcorr', **kwargs)\n</code></pre> <p>Apply baseline correction to the chromatogram data</p> <p>Parameters:</p> <ul> <li> <code>correction_func</code>           \u2013            <p>Function that takes a pandas DataFrame and returns corrected Series</p> </li> <li> <code>inplace</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, modify the original data. If False, add new column</p> </li> <li> <code>suffix</code>               (<code>str</code>, default:                   <code>'_BLcorr'</code> )           \u2013            <p>Suffix to add to the new column name when inplace=False</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>pd.DataFrame: The corrected data (same as self.data if inplace=True)</p> </li> </ul> Source code in <code>chromstream/objects.py</code> <pre><code>def apply_baseline(\n    self, correction_func, inplace=False, suffix=\"_BLcorr\", **kwargs\n):\n    \"\"\"\n    Apply baseline correction to the chromatogram data\n\n    Args:\n        correction_func: Function that takes a pandas DataFrame and returns corrected Series\n        inplace (bool): If True, modify the original data. If False, add new column\n        suffix (str): Suffix to add to the new column name when inplace=False\n\n    Returns:\n        pd.DataFrame: The corrected data (same as self.data if inplace=True)\n    \"\"\"\n    signal_column = self.data.columns[1]  # Second column (signal data)\n\n    # Apply the correction function - passes entire DataFrame\n    corrected_signal = correction_func(self.data, **kwargs)\n\n    if inplace:\n        self.data[signal_column] = corrected_signal\n    else:\n        new_column_name = signal_column + suffix\n        self.data[new_column_name] = corrected_signal\n\n    return self.data\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram.integrate_peaks","title":"integrate_peaks","text":"<pre><code>integrate_peaks(peaklist: dict, column: None | str = None) -&gt; dict\n</code></pre> <p>Integrate peaks for this chromatogram</p> <p>Parameters:</p> <ul> <li> <code>peaklist</code>               (<code>dict</code>)           \u2013            <p>Dictionary defining the peaks to integrate. Example:</p> </li> <li> <code>Peaks_TCD = {\"N2\"</code>           \u2013            <p>[20, 26], \"H2\": [16, 19]}</p> </li> <li> <code>column</code>               (<code>None | str</code>, default:                   <code>None</code> )           \u2013            <p>Optional column name to use for integration. If None, uses second column.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>Dictionary with integrated peak areas and timestamp</p> </li> </ul> Source code in <code>chromstream/objects.py</code> <pre><code>def integrate_peaks(self, peaklist: dict, column: None | str = None) -&gt; dict:\n    \"\"\"\n    Integrate peaks for this chromatogram\n\n    Args:\n        peaklist: Dictionary defining the peaks to integrate. Example:\n        Peaks_TCD = {\"N2\": [20, 26], \"H2\": [16, 19]}\n        The list values must be in the same unit as the chromatogram.\n        column: Optional column name to use for integration. If None, uses second column.\n\n    Returns:\n        Dictionary with integrated peak areas and timestamp\n    \"\"\"\n    from .data_processing import integrate_single_chromatogram\n\n    return integrate_single_chromatogram(self, peaklist, column=column)\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Chromatogram.plot","title":"plot","text":"<pre><code>plot(ax=None, column=None, **kwargs)\n</code></pre> <p>Plot the chromatogram data</p> Source code in <code>chromstream/objects.py</code> <pre><code>def plot(self, ax=None, column=None, **kwargs):\n    \"\"\"Plot the chromatogram data\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    # Choose which column to plot (default to second column)\n    y_column = self.data.columns[1] if column is None else column\n    x_column = self.data.columns[0]\n\n    ax.plot(self.data[x_column], self.data[y_column], **kwargs)\n    ax.set_xlabel(x_column)\n    ax.set_ylabel(y_column)\n    ax.set_title(f\"Chromatogram - {self.channel} - {self.path}\")\n\n    return ax\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment","title":"Experiment  <code>dataclass</code>","text":"<pre><code>Experiment(name: str, channels: dict[str, ChannelChromatograms] = dict(), experiment_starttime: Timestamp | None = None, experiment_endtime: Timestamp | None = None, log: DataFrame | None = None)\n</code></pre> <p>Data for a single experiment containing multiple on-line GC channels</p>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.channel_names","title":"channel_names  <code>property</code>","text":"<pre><code>channel_names: list[str]\n</code></pre> <p>Get a list of channel names in the experiment</p>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.channels","title":"channels  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>channels: dict[str, ChannelChromatograms] = field(default_factory=dict)\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.experiment_endtime","title":"experiment_endtime  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>experiment_endtime: Timestamp | None = None\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.experiment_starttime","title":"experiment_starttime  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>experiment_starttime: Timestamp | None = None\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.log","title":"log  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>log: DataFrame | None = None\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.log_data","title":"log_data  <code>property</code>","text":"<pre><code>log_data: DataFrame\n</code></pre> <p>Get log data, raising an error if not available</p>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.add_channel","title":"add_channel","text":"<pre><code>add_channel(channel_name: str, channel_data: ChannelChromatograms)\n</code></pre> <p>Add a channel to the experiment</p> Source code in <code>chromstream/objects.py</code> <pre><code>def add_channel(self, channel_name: str, channel_data: ChannelChromatograms):\n    \"\"\"Add a channel to the experiment\"\"\"\n    self.channels[channel_name] = channel_data\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.add_chromatogram","title":"add_chromatogram","text":"<pre><code>add_chromatogram(chromatogram: Path | str | Chromatogram, channel_name: str | None = None)\n</code></pre> <p>Add a chromatogram to the experiment, automatically creating the channel if it does not exist</p> <p>Parameters:</p> <ul> <li> <code>chromatogram</code>               (<code>Path | str | Chromatogram</code>)           \u2013            <p>Path to the chromatogram file or a Chromatogram object</p> </li> <li> <code>channel_name</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Optional channel name to override</p> </li> </ul> Source code in <code>chromstream/objects.py</code> <pre><code>def add_chromatogram(\n    self, chromatogram: Path | str | Chromatogram, channel_name: str | None = None\n):\n    \"\"\"Add a chromatogram to the experiment, automatically creating the channel if it does not exist\n\n    Args:\n        chromatogram (Path | str | Chromatogram): Path to the chromatogram file or a Chromatogram object\n        channel_name (Optional[str], optional): Optional channel name to override\n\n\n    \"\"\"\n    if isinstance(chromatogram, (str, Path)):\n        from .parsers import parse_chromatogram_txt\n\n        chrom = parse_chromatogram_txt(chromatogram)\n    elif isinstance(chromatogram, Chromatogram):\n        chrom = chromatogram\n    else:\n        raise ValueError(\n            \"chromatogram must be a file path or a Chromatogram object\"\n        )\n\n    channel = channel_name if channel_name else chrom.channel\n\n    if channel not in self.channels:\n        self.channels[channel] = ChannelChromatograms(channel=channel)\n\n    injection_num = len(self.channels[channel].chromatograms)\n    self.channels[channel].add_chromatogram(injection_num, chrom)\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.add_log","title":"add_log","text":"<pre><code>add_log(log: str | Path | DataFrame)\n</code></pre> <p>Adds a log dataframe to the experiment, either from a dataframe or from a path to the log file.</p> <p>Parameters:</p> <ul> <li> <code>log</code>               (<code>str | Path | DataFrame</code>)           \u2013            <p>Path to the log file or a DataFrame</p> </li> </ul> Source code in <code>chromstream/objects.py</code> <pre><code>def add_log(self, log: str | Path | pd.DataFrame):\n    \"\"\"\n    Adds a log dataframe to the experiment, either from a dataframe or from a path to the log file.\n\n    Args:\n        log (str | Path | pd.DataFrame): Path to the log file or a DataFrame\n    \"\"\"\n    if isinstance(log, (str, Path)):\n        from .parsers import parse_log_file\n\n        self.log = parse_log_file(log)\n    elif isinstance(log, pd.DataFrame):\n        self.log = log\n    else:\n        raise ValueError(\"log must be a file path or a DataFrame\")\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.plot_chromatograms","title":"plot_chromatograms","text":"<pre><code>plot_chromatograms(ax=None, channels: str | list = 'all', **kwargs)\n</code></pre> Source code in <code>chromstream/objects.py</code> <pre><code>def plot_chromatograms(self, ax=None, channels: str | list = \"all\", **kwargs):\n    if ax is None:\n        n_channels_to_plot = (\n            len(self.channels) if channels == \"all\" else len(channels)\n        )\n\n        # Handle empty experiment case\n        if n_channels_to_plot == 0:\n            fig, ax = plt.subplots()\n            ax.text(\n                0.5,\n                0.5,\n                \"No channels to plot\",\n                ha=\"center\",\n                va=\"center\",\n                transform=ax.transAxes,\n            )\n            ax.set_title(\"Empty Experiment\")\n            return\n\n        fig, ax = plt.subplots(\n            n_channels_to_plot,\n            1,\n            # figsize=(7, 3.3 / 1.618 * n_channels_to_plot),\n            tight_layout=True,\n        )\n        if n_channels_to_plot == 1:\n            ax = [ax]\n    if channels == \"all\":\n        channels = list(self.channels.keys())\n    for i, channel in enumerate(channels):\n        if channel in self.channels:\n            self.channels[channel].plot(ax=ax[i], **kwargs)\n        else:\n            raise ValueError(f\"Channel {channel} not found in experiment.\")\n</code></pre>"},{"location":"reference/chromstream/objects.html#chromstream.objects.Experiment.plot_log","title":"plot_log","text":"<pre><code>plot_log(columns: str | list, ax=None, use_exp_time=False)\n</code></pre> <p>Plots specified colums of the experiment log. If use_exp_time is True, the x-axis will be the time since the start of the experiment in minutes. Args:     columns (str | list): Column name or list of column names to plot     ax (matplotlib.axes.Axes, optional): Axes to plot on. If None, a new figure and axes will be created.     use_exp_time (bool, optional): Whether to use time since start of experiment as x-axis. Defaults to False.</p> Source code in <code>chromstream/objects.py</code> <pre><code>def plot_log(self, columns: str | list, ax=None, use_exp_time=False):\n    \"\"\"\n    Plots specified colums of the experiment log. If use_exp_time is True, the x-axis will be the time since the start of the experiment in minutes.\n    Args:\n        columns (str | list): Column name or list of column names to plot\n        ax (matplotlib.axes.Axes, optional): Axes to plot on. If None, a new figure and axes will be created.\n        use_exp_time (bool, optional): Whether to use time since start of experiment as x-axis. Defaults to False.\n    \"\"\"\n\n    if self.log is None:\n        raise ValueError(\"No log data available to plot.\")\n\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    if isinstance(columns, str):\n        columns = [columns]\n\n    if use_exp_time:\n        if self.experiment_starttime is None:\n            raise ValueError(\n                \"Experiment start time is not set. Cannot use experiment time.\"\n            )\n        x = (\n            pd.to_datetime(self.log[\"Timestamp\"]) - self.experiment_starttime\n        ).dt.total_seconds() / 60.0\n        x_label = \"Experiment Time (min)\"\n    else:\n        x = self.log[\"Timestamp\"]\n        x_label = \"Timestamp\"\n\n    for col in columns:\n        if col not in self.log.columns:\n            raise ValueError(f\"Column {col} not found in log data.\")\n        ax.plot(x, self.log[col], label=col)\n\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(\"Value\")\n    ax.set_title(\"Experiment Log Data\")\n    ax.legend()\n\n    return ax\n</code></pre>"},{"location":"reference/chromstream/parsers.html","title":"parsers","text":""},{"location":"reference/chromstream/parsers.html#chromstream.parsers.detect_log_type","title":"detect_log_type","text":"<pre><code>detect_log_type(file_path: str | Path) -&gt; str\n</code></pre> <p>Detect the type of log file based on its structure and content.</p> <p>Parameters:</p> <ul> <li> <code>file_path</code>               (<code>str | Path</code>)           \u2013            <p>Path to the log file</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>String indicating the log type ('FT', 'HTHPIR', 'LPIR', 'Robert', 'unknown')</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def detect_log_type(file_path: str | Path) -&gt; str:\n    \"\"\"\n    Detect the type of log file based on its structure and content.\n\n    Args:\n        file_path: Path to the log file\n\n    Returns:\n        String indicating the log type ('FT', 'HTHPIR', 'LPIR', 'Robert', 'unknown')\n    \"\"\"\n    file_path = Path(file_path)\n\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        content = f.read()\n        lines = [\n            line.strip() for line in content.split(\"\\n\")[:20]\n        ]  # Read first 20 lines\n\n    # Check for FT type - has many columns including MFC, valve info\n    if any(\"MFC\" in line and \"Valve\" in line for line in lines):\n        return \"FT\"\n\n    # Check for HTHPIR type - has C2H4/CH4 column and specific format\n    if \"C2H4/CH4\" in content or any(\"C2H4/CH4\" in line for line in lines):\n        return \"HTHPIR\"\n\n    # Check for LPIR type - has N2-bub column\n    if any(\"N2-bub\" in line for line in lines):\n        return \"LPIR\"\n\n    # Check for Robert type - has \"Power Out %\" and \"Stirrer\" columns\n    if any(\"Power Out %\" in line and \"Stirrer\" in line for line in lines):\n        return \"Robert\"\n\n    return \"unknown\"\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_MTO_asc","title":"parse_MTO_asc","text":"<pre><code>parse_MTO_asc(Path: str | Path) -&gt; tuple[Chromatogram, Chromatogram, Chromatogram]\n</code></pre> <p>Parses an ASCII file. from the MTO setup. The file contains the chromatograms for all channels under each other.</p> <p>Parameters:</p> <ul> <li> <code>Path</code>               (<code>str | Path</code>)           \u2013            <p>Path to the chromatogram file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[Chromatogram, Chromatogram, Chromatogram]</code>           \u2013            <p>The Chromatogram objects.</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_MTO_asc(Path: str | Path) -&gt; tuple[Chromatogram, Chromatogram, Chromatogram]:\n    \"\"\"\n    Parses an ASCII file. from the MTO setup. The file contains the chromatograms for all channels under each other.\n\n    Args:\n        Path (str | Path): Path to the chromatogram file.\n\n    Returns:\n        The Chromatogram objects.\n    \"\"\"\n    # Reads the ascii file of the injection. Splits in into a metadate frame and a frame containing chromatograms of the 3 channels.\n    # Sampling frequency must be equal for all channels.\n\n    df_chromatogram = pd.read_csv(Path, sep=\"\\t\", header=None, skiprows=13)\n    metadata = parse_MTO_metadata(Path)\n    # hard coding the signal unit as mV\n    # The metadata contains a field \"Y Axis Title\"  'mVolts,mVolts,mVolts'\n    metadata[\"Signal Unit\"] = \"mV\"\n\n    # split the chromatogram into the different columns. This is achieved by splitting the frame at indexes matching 1/3 and 2/3 of the lenght\n    df_Channel_1 = df_chromatogram.iloc[0 : int(len(df_chromatogram) / 3)].reset_index(\n        drop=True\n    )\n    df_Channel_2 = df_chromatogram.iloc[\n        int(len(df_chromatogram) / 3) : int(2 * len(df_chromatogram) / 3)\n    ].reset_index(drop=True)\n    df_Channel_3 = df_chromatogram.iloc[\n        int(2 * len(df_chromatogram) / 3) : len(df_chromatogram)\n    ].reset_index(drop=True)\n\n    # combine the 3 Channels into one frame, new index\n    df_chromatogram = pd.concat([df_Channel_1, df_Channel_2, df_Channel_3], axis=1)\n    sampling_freqs = [\n        float(x.strip()) for x in metadata[\"Sampling Rate\"].split(\",\")[0:2]\n    ]\n\n    if len(set(sampling_freqs)) != 1:\n        raise ValueError(\"The sampling frequencies are not equal\")\n\n    sampling_freq = 1 / sampling_freqs[0]  # Hz\n\n    df_chromatogram[\"Time[s]\"] = df_chromatogram.index * sampling_freq\n\n    # set time as index\n    df_chromatogram = df_chromatogram.set_index(\"Time[s]\")\n    df_chromatogram[\"Time[s]\"] = df_chromatogram.index\n\n    # getting injection time\n    inj_time = pd.to_datetime(metadata.get(\"Acquisition Date and Time\", \"\"))\n\n    df_chromatogram.columns = [\"FID_L\", \"FID_M\", \"TCD\", \"Time[s]\"]\n    Chromatogram1 = Chromatogram(\n        df_chromatogram[[\"Time[s]\", \"FID_L\"]],\n        injection_time=inj_time,\n        metadata=metadata,\n        channel=\"FID_L\",\n        path=Path,\n    )\n    Chromatogram2 = Chromatogram(\n        df_chromatogram[[\"Time[s]\", \"FID_M\"]],\n        injection_time=inj_time,\n        metadata=metadata,\n        channel=\"FID_M\",\n        path=Path,\n    )\n    Chromatogram3 = Chromatogram(\n        df_chromatogram[[\"Time[s]\", \"TCD\"]],\n        injection_time=inj_time,\n        metadata=metadata,\n        channel=\"TCD\",\n        path=Path,\n    )\n    return Chromatogram1, Chromatogram2, Chromatogram3\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_MTO_metadata","title":"parse_MTO_metadata","text":"<pre><code>parse_MTO_metadata(Path: str | Path) -&gt; dict\n</code></pre> <p>Parses the metadata section from an MTO ASCII file and returns it as a dictionary.</p> <p>Parameters:</p> <ul> <li> <code>Path</code>               (<code>str | Path</code>)           \u2013            <p>Path to the chromatogram file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>Dictionary containing metadata with cleaned keys and processed values.</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_MTO_metadata(Path: str | Path) -&gt; dict:\n    \"\"\"\n    Parses the metadata section from an MTO ASCII file and returns it as a dictionary.\n\n    Args:\n        Path (str | Path): Path to the chromatogram file.\n\n    Returns:\n        dict: Dictionary containing metadata with cleaned keys and processed values.\n    \"\"\"\n    df_chromatogram_meta = pd.read_csv(\n        Path, sep=\"\\t\", header=None, skiprows=0, nrows=13\n    )\n\n    # Convert metadata DataFrame to dictionary\n    metadata = {}\n    for _, row in df_chromatogram_meta.iterrows():\n        if pd.notna(row[0]):\n            # Split on first comma to separate key from values\n            parts = str(row[0]).split(\",\", 1)\n            if len(parts) == 2:\n                key = parts[0].strip().rstrip(\":\")\n                value = parts[1].strip()\n                # If there are multiple comma-separated values, keep as string or convert to list\n                if \",\" in value:\n                    # For values like sampling rates, convert to list of numbers where possible\n                    try:\n                        value_list = [\n                            float(x.strip()) for x in value.split(\",\") if x.strip()\n                        ]\n                        metadata[key] = (\n                            value_list if len(value_list) &gt; 1 else value_list[0]\n                        )\n                    except ValueError:\n                        # If conversion fails, keep as comma-separated string\n                        metadata[key] = value\n                else:\n                    metadata[key] = value\n    # adding time unit to metadata\n    metadata[\"time_unit\"] = \"s\"\n    return metadata\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_chromatogram_txt","title":"parse_chromatogram_txt","text":"<pre><code>parse_chromatogram_txt(path: str | Path) -&gt; Chromatogram\n</code></pre> <p>Parses a txt file exported using chromeleon software into a Chromatogram object.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>str | Path</code>)           \u2013            <p>Path to the chromatogram file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Chromatogram</code> (              <code>Chromatogram</code> )          \u2013            <p>Parsed Chromatogram object.</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_chromatogram_txt(path: str | Path) -&gt; Chromatogram:\n    \"\"\"\n    Parses a txt file exported using chromeleon software into a Chromatogram object.\n\n    Args:\n        path (str | Path): Path to the chromatogram file.\n\n    Returns:\n        Chromatogram: Parsed Chromatogram object.\n    \"\"\"\n    metadata, df = parse_chromeleon_txt(path)\n    injection_time = pd.Timestamp(metadata[\"Inject Time\"])\n    channel = metadata.get(\"Channel\", \"unknown\")\n    path = Path(path)\n\n    return Chromatogram(\n        data=df,\n        injection_time=injection_time,\n        metadata=metadata,\n        channel=channel,\n        path=path,\n    )\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_chromeleon_txt","title":"parse_chromeleon_txt","text":"<pre><code>parse_chromeleon_txt(file_path: str | Path) -&gt; tuple[dict[str, str], DataFrame]\n</code></pre> <p>Parses a txt file exporeted using chromeleon software into a dict of metadata and pd.DataFrame for chromatogram data.</p> <p>Parameters:</p> <ul> <li> <code>file_path</code>               (<code>str | Path</code>)           \u2013            <p>Path to the chromatogram file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[dict[str, str], DataFrame]</code>           \u2013            <p>Tuple[Dict[str, str], pd.DataFrame]: A tuple containing metadata and chromatogram data as a DataFrame.</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_chromeleon_txt(file_path: str | Path) -&gt; tuple[dict[str, str], pd.DataFrame]:\n    \"\"\"\n    Parses a txt file exporeted using chromeleon software into a dict of metadata and pd.DataFrame for chromatogram data.\n\n    Args:\n        file_path (str | Path): Path to the chromatogram file.\n\n    Returns:\n        Tuple[Dict[str, str], pd.DataFrame]: A tuple containing metadata and chromatogram data as a DataFrame.\n    \"\"\"\n    metadata = {}\n    chromatogram_data_start = None\n\n    with open(file_path, \"r\") as file:\n        lines = file.readlines()\n\n    # Regular expression to match metadata lines\n    metadata_pattern = re.compile(r\"^(?P&lt;key&gt;[^\\t]+?)\\s*[:\\t]\\s*(?P&lt;value&gt;.+)$\")\n\n    # Parse metadata\n    metadata_section = True\n    for i, line in enumerate(lines):\n        line = line.strip()\n        if not line:\n            continue\n        if metadata_section:\n            if line.startswith(\"Chromatogram Data:\"):\n                chromatogram_data_start = i + 2  # Skip the header line\n                metadata_section = False\n                continue\n            match = metadata_pattern.match(line)\n            if match:\n                key = match.group(\"key\").strip()\n                value = match.group(\"value\").strip()\n                metadata[key] = value\n        else:\n            break\n\n    # adding injection time as datetime object\n    # Note: Some files use \"Inject Time\", others \"Injection Time\"\n    inject_time_key = None\n    if \"Inject Time\" in metadata:\n        inject_time_key = \"Inject Time\"\n    elif \"Injection Time\" in metadata:\n        inject_time_key = \"Injection Time\"\n\n    if inject_time_key is None:\n        log.warning(\"Inject Time or Injection Time is missing from the metadata.\")\n    else:\n        try:\n            metadata[\"Inject Time\"] = parse_inject_time(\n                metadata[inject_time_key], metadata\n            )\n        except Exception as e:\n            log.warning(f\"Failed to parse '{inject_time_key}': {e}\")\n\n    # getting signal unit\n    if \"Signal Unit\" not in metadata:\n        log.warning(\"Signal Unit is missing from the metadata.\")\n        signal_unit = \"unknown\"\n    else:\n        signal_unit = metadata[\"Signal Unit\"]\n\n    # reading chromatogram data\n    if chromatogram_data_start is not None:\n        # Check first data line to determine number format\n        with open(file_path, \"r\") as f:\n            lines = f.readlines()\n\n        first_data_line = lines[chromatogram_data_start].strip()\n        comma_decimal_format = \",\" in first_data_line\n\n        if comma_decimal_format:\n            # European format: comma as decimal, dot as thousands\n            converters = {\n                \"Time (min)\": lambda x: float(str(x).replace(\".\", \"\").replace(\",\", \".\"))\n                if pd.notna(x) and x != \"\"\n                else float(\"nan\"),\n                f\"Value ({signal_unit})\": lambda x: float(\n                    str(x).replace(\".\", \"\").replace(\",\", \".\")\n                )\n                if pd.notna(x) and x != \"\"\n                else float(\"nan\"),\n            }\n        else:\n            # Standard format: dot as decimal, comma as thousands\n            converters = {\n                \"Time (min)\": lambda x: float(str(x).replace(\",\", \"\"))\n                if pd.notna(x) and x != \"\"\n                else float(\"nan\"),\n                f\"Value ({signal_unit})\": lambda x: float(str(x).replace(\",\", \"\"))\n                if pd.notna(x) and x != \"\"\n                else float(\"nan\"),\n            }\n\n        chromatogram_df = pd.read_csv(\n            file_path,\n            sep=\"\t\",\n            skiprows=chromatogram_data_start,\n            names=[\"Time (min)\", \"Step (s)\", f\"Value ({signal_unit})\"],\n            na_values=[\"n.a.\"],\n            usecols=[\"Time (min)\", f\"Value ({signal_unit})\"],\n            converters=converters,\n        )\n        # adding time units to metadata\n        metadata[\"time_unit\"] = \"min\"\n    else:\n        log.warning(f\"Chromatogram data section not found for {file_path}.\")\n        chromatogram_df = pd.DataFrame()\n\n    # adding time unit to the metadata\n\n    return metadata, chromatogram_df\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_inject_time","title":"parse_inject_time","text":"<pre><code>parse_inject_time(inject_time: str, metadata: dict) -&gt; Timestamp\n</code></pre> <p>Parses the injeciton time for chromeleon txt files into a pd.Timestamp object. The file most likely adopts the datatime format of the machine, meaning it can be very different between machines. In some formats, the date is saved seperatly from the datatime, and needs to be combined.</p> <p>Parameters:</p> <ul> <li> <code>inject_time</code>               (<code>Timestamp</code>)           \u2013            <p>The Inject Time timestamp to parse.</p> </li> <li> <code>metadata</code>               (<code>dict</code>)           \u2013            <p>Metadata dictionary containing additional information.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Timestamp</code>           \u2013            <p>pd.Timestamp: Parsed datetime object.</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_inject_time(inject_time: str, metadata: dict) -&gt; pd.Timestamp:\n    \"\"\"\n    Parses the injeciton time for chromeleon txt files into a pd.Timestamp object.\n    The file most likely adopts the datatime format of the machine, meaning it can be very different between machines.\n    In some formats, the date is saved seperatly from the datatime, and needs to be combined.\n\n    Args:\n        inject_time (pd.Timestamp): The Inject Time timestamp to parse.\n        metadata (dict): Metadata dictionary containing additional information.\n\n    Returns:\n        pd.Timestamp: Parsed datetime object.\n    \"\"\"\n    # Check for format like '7/17/2023 3:35:22 PM +02:00'\n    if re.match(\n        r\"\\d{1,2}/\\d{1,2}/\\d{4} \\d{1,2}:\\d{2}:\\d{2} (AM|PM) \\+\\d{2}:\\d{2}\", inject_time\n    ):\n        return pd.to_datetime(inject_time).tz_localize(None)\n\n    # Check for format like '17-1-2023 16:45:42 +01:00'\n    if re.match(r\"\\d{1,2}-\\d{1,2}-\\d{4} \\d{2}:\\d{2}:\\d{2} \\+\\d{2}:\\d{2}\", inject_time):\n        return pd.to_datetime(inject_time, format=\"%d-%m-%Y %H:%M:%S %z\").tz_localize(\n            None\n        )\n\n    # Check for format like '1:43:35 PM' and require metadata for the date\n    if re.match(r\"\\d{1,2}:\\d{2}:\\d{2} (AM|PM)\", inject_time):\n        if \"Injection Date\" in metadata:\n            injection_date = metadata[\"Injection Date\"]\n            combined_datetime = f\"{injection_date} {inject_time}\"\n            return pd.to_datetime(combined_datetime, format=\"%m/%d/%Y %I:%M:%S %p\")\n        else:\n            raise ValueError(\n                \"Injection Date is missing from metadata for AM/PM time format.\"\n            )\n\n    # Check for format like '10:30:07' (24-hour) and require metadata for the date\n    if re.match(r\"\\d{2}:\\d{2}:\\d{2}$\", inject_time):\n        if \"Injection Date\" in metadata:\n            injection_date = metadata[\"Injection Date\"]\n            # Check if date is in format like '22-Aug-25'\n            if re.match(r\"\\d{1,2}-[A-Za-z]{3}-\\d{2}\", injection_date):\n                combined_datetime = f\"{injection_date} {inject_time}\"\n                return pd.to_datetime(combined_datetime, format=\"%d-%b-%y %H:%M:%S\")\n            # Check if date is in format like '12/19/2023'\n            elif re.match(r\"\\d{1,2}/\\d{1,2}/\\d{4}\", injection_date):\n                combined_datetime = f\"{injection_date} {inject_time}\"\n                return pd.to_datetime(combined_datetime, format=\"%m/%d/%Y %H:%M:%S\")\n            else:\n                raise ValueError(\n                    f\"Unrecognized Injection Date format: {injection_date}\"\n                )\n        else:\n            raise ValueError(\n                \"Injection Date is missing from metadata for time-only Inject Time.\"\n            )\n    else:\n        try:\n            # Attempt to parse as ISO 8601 format\n            time = pd.to_datetime(inject_time).tz_localize(None)\n            log.info(f\"Time format not handled, but succeeded parsing with: {time}\")\n            return time\n        except Exception:\n            pass\n    raise ValueError(f\"Unrecognized Inject Time format: {inject_time}\")\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_log_MTO","title":"parse_log_MTO","text":"<pre><code>parse_log_MTO(file_path: str | Path) -&gt; DataFrame\n</code></pre> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_log_MTO(file_path: str | Path) -&gt; pd.DataFrame:\n    Log = pd.read_csv(file_path, sep=\"\\t\", skiprows=1)\n    Log = Log[\n        [\n            \"Date\",\n            \"Time\",\n            \"MFC 1 pv\",\n            \"MFC 2 pv\",\n            \"MFC 3 pv\",\n            \"MFC 4 pv\",\n            \"Oven Temperature\",\n            \"v11-reactor\",\n            \"v10-bubbler\",\n            \"v12-gc\",\n        ]\n    ]\n    # for the v-11 reactor columns, replace all 0 with 'reactor' else 'bypass'\n    Log[\"v11-reactor\"] = Log[\"v11-reactor\"].apply(\n        lambda x: \"reactor\" if x == 0 else \"bypass\"\n    )\n    Log.rename(columns={\"MFC 1 pv\": \"N2_flow\"}, inplace=True)\n    Log.rename(columns={\"MFC 4 pv\": \"He_Bubbler\"}, inplace=True)\n    Log.rename(columns={\"MFC 3 pv\": \"He_Dilution\"}, inplace=True)\n    Log[\"Timestamp\"] = pd.to_datetime(\n        Log[\"Date\"] + \" \" + Log[\"Time\"], format=\"%m/%d/%Y %I:%M:%S %p\"\n    )\n    Log[\"Timestamp\"] = Log.apply(\n        lambda row: datetime.strptime(\n            row[\"Date\"] + \" \" + row[\"Time\"], \"%m/%d/%Y %I:%M:%S %p\"\n        ),\n        axis=1,\n    )\n    return Log\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_log_file","title":"parse_log_file","text":"<pre><code>parse_log_file(file_path: str | Path) -&gt; DataFrame\n</code></pre> <p>Automatically detect and parse any supported log file type. To be extended.</p> <p>Parameters:</p> <ul> <li> <code>file_path</code>               (<code>str | Path</code>)           \u2013            <p>Path to the log file</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>Parsed DataFrame with metadata as attributes</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the file type is not recognized or supported</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_log_file(file_path: str | Path) -&gt; pd.DataFrame:\n    \"\"\"\n    Automatically detect and parse any supported log file type. To be extended.\n\n    Args:\n        file_path: Path to the log file\n\n    Returns:\n        Parsed DataFrame with metadata as attributes\n\n    Raises:\n        ValueError: If the file type is not recognized or supported\n    \"\"\"\n    file_path = Path(file_path)\n\n    if not file_path.exists():\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n\n    log_type = detect_log_type(file_path)\n\n    if log_type == \"FT\":\n        return parse_log_type_ft(file_path)\n    elif log_type == \"HTHPIR\":\n        return parse_log_type_hthpir(file_path)\n    elif log_type == \"LPIR\":\n        return parse_log_type_lpir(file_path)\n    elif log_type == \"Robert\":\n        return parse_log_type_robert(file_path)\n    else:\n        raise ValueError(\n            f\"Unsupported or unrecognized log file type: {log_type}. Parse the data manually.\"\n        )\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_log_type_ft","title":"parse_log_type_ft","text":"<pre><code>parse_log_type_ft(file_path: str | Path) -&gt; DataFrame\n</code></pre> <p>Parse FT type log files.</p> <p>Parameters:</p> <ul> <li> <code>file_path</code>               (<code>str | Path</code>)           \u2013            <p>Path to the FT log file</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>Parsed DataFrame with metadata as attributes</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_log_type_ft(file_path: str | Path) -&gt; pd.DataFrame:\n    \"\"\"\n    Parse FT type log files.\n\n    Args:\n        file_path: Path to the FT log file\n\n    Returns:\n        Parsed DataFrame with metadata as attributes\n    \"\"\"\n    file_path = Path(file_path)\n\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        lines = [line.strip() for line in f.readlines()]\n\n    # Find where the data starts\n    data_start_idx = None\n    for i, line in enumerate(lines):\n        if line.startswith(\"Date/Time\"):\n            data_start_idx = i\n            break\n\n    if data_start_idx is None:\n        raise ValueError(\"Could not find data section in FT log file\")\n\n    # Parse metadata\n    metadata = parse_metadata_section(lines[:data_start_idx])\n\n    # Read the data using pandas\n    df = pd.read_csv(file_path, sep=\"\\t\", skiprows=data_start_idx)\n\n    # Parse datetime\n    df[\"Timestamp\"] = pd.to_datetime(df[\"Date/Time\"], format=\"%d-%b-%Y %H:%M:%S\")\n    df = df.drop(\"Date/Time\", axis=1)\n\n    # Add metadata as attributes\n    df.attrs.update(metadata.items())  # ignore\n\n    return df\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_log_type_hthpir","title":"parse_log_type_hthpir","text":"<pre><code>parse_log_type_hthpir(file_path: str | Path) -&gt; DataFrame\n</code></pre> <p>Parse HTHPIR type log files.</p> <p>Parameters:</p> <ul> <li> <code>file_path</code>               (<code>str | Path</code>)           \u2013            <p>Path to the HTHPIR log file</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>Parsed DataFrame with metadata as attributes</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_log_type_hthpir(file_path: str | Path) -&gt; pd.DataFrame:\n    \"\"\"\n    Parse HTHPIR type log files.\n\n    Args:\n        file_path: Path to the HTHPIR log file\n\n    Returns:\n        Parsed DataFrame with metadata as attributes\n    \"\"\"\n    file_path = Path(file_path)\n\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        lines = [line.rstrip() for line in f.readlines()]  # Keep trailing tabs\n\n    # Find where the data starts - look for actual data rows (start with date)\n    data_start_idx = None\n    header_lines = []\n\n    for i, line in enumerate(lines):\n        # Look for lines that start with a date pattern like \"1/17/2023\"\n        if re.match(r\"^\\d{1,2}/\\d{1,2}/\\d{4}\\t\", line):\n            data_start_idx = i\n            break\n        # Collect potential header lines that contain column information\n        if (\n            \"Date\" in line\n            or \"Time\" in line\n            or \"Oven\" in line\n            or \"N2\" in line\n            or \"sp\" in line\n        ):\n            header_lines.append(line)\n\n    if data_start_idx is None:\n        raise ValueError(\"Could not find data section in HTHPIR log file\")\n\n    # Parse metadata - everything before the data section\n    metadata = parse_metadata_section(lines[:data_start_idx])\n\n    # Manually construct the column names from the header lines\n    # The HTHPIR format has split headers, so we need to reconstruct them\n    column_names = [\n        \"Date\",\n        \"Time\",\n        \"Oven sp\",\n        \"Oven temp\",\n        \"Oven ramp\",\n        \"N2 sp\",\n        \"N2 flow\",\n        \"H2 sp\",\n        \"H2 flow\",\n        \"CO2 sp\",\n        \"CO2 flow\",\n        \"C2H4/CH4 sp\",\n        \"C2H4/CH4 flow\",\n        \"O2 sp\",\n        \"O2 pv\",\n        \"Pressure sp\",\n        \"Pressure pv\",\n    ]\n\n    # Read the data section manually\n    data_rows = []\n    for line in lines[data_start_idx:]:\n        if line.strip():  # Skip empty lines\n            row = line.split(\"\\t\")\n            data_rows.append(row)\n\n    # Create DataFrame\n    df = pd.DataFrame(data_rows, columns=column_names[: len(data_rows[0])])\n\n    # Convert numeric columns\n    for col in df.columns:\n        if col not in [\"Date\", \"Time\"]:\n            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n\n    # Combine Date and Time columns - handle AM/PM format\n    df[\"Timestamp\"] = pd.to_datetime(\n        df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str)\n    )\n    df = df.drop([\"Date\", \"Time\"], axis=1)\n\n    # Add metadata as attributes\n    df.attrs.update(metadata.items())\n\n    return df\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_log_type_lpir","title":"parse_log_type_lpir","text":"<pre><code>parse_log_type_lpir(file_path: str | Path) -&gt; DataFrame\n</code></pre> <p>Parse LPIR type log files.</p> <p>Parameters:</p> <ul> <li> <code>file_path</code>               (<code>str | Path</code>)           \u2013            <p>Path to the LPIR log file</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>Parsed DataFrame with metadata as attributes</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_log_type_lpir(file_path: str | Path) -&gt; pd.DataFrame:\n    \"\"\"\n    Parse LPIR type log files.\n\n    Args:\n        file_path: Path to the LPIR log file\n\n    Returns:\n        Parsed DataFrame with metadata as attributes\n    \"\"\"\n    file_path = Path(file_path)\n\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        lines = [line.strip() for line in f.readlines()]\n\n    # Find where the data starts\n    data_start_idx = None\n    for i, line in enumerate(lines):\n        if \"Date\\tTime\" in line:\n            data_start_idx = i\n            break\n\n    if data_start_idx is None:\n        raise ValueError(\"Could not find data section in LPIR log file\")\n\n    # Parse metadata\n    metadata = parse_metadata_section(lines[:data_start_idx])\n\n    # Read the data using pandas\n    df = pd.read_csv(file_path, sep=\"\\t\", skiprows=data_start_idx)\n\n    # Combine Date and Time columns\n    df[\"Timestamp\"] = pd.to_datetime(\n        df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str)\n    )\n    df = df.drop([\"Date\", \"Time\"], axis=1)\n\n    # Add metadata as attributes\n    df.attrs.update(metadata.items())  # ignore\n\n    return df\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_log_type_robert","title":"parse_log_type_robert","text":"<pre><code>parse_log_type_robert(file_path: str | Path) -&gt; DataFrame\n</code></pre> <p>Parse Robert type log files.</p> <p>Parameters:</p> <ul> <li> <code>file_path</code>               (<code>str | Path</code>)           \u2013            <p>Path to the Robert log file</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>Parsed DataFrame with metadata as attributes</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_log_type_robert(file_path: str | Path) -&gt; pd.DataFrame:\n    \"\"\"\n    Parse Robert type log files.\n\n    Args:\n        file_path: Path to the Robert log file\n\n    Returns:\n        Parsed DataFrame with metadata as attributes\n    \"\"\"\n    file_path = Path(file_path)\n\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        lines = [line.strip() for line in f.readlines()]\n\n    # Find where the data starts\n    data_start_idx = None\n    for i, line in enumerate(lines):\n        if \"Date\\tTime\" in line:\n            data_start_idx = i\n            break\n\n    if data_start_idx is None:\n        raise ValueError(\"Could not find data section in Robert log file\")\n\n    # Parse metadata\n    metadata = parse_metadata_section(lines[:data_start_idx])\n\n    # Read the data using pandas\n    df = pd.read_csv(file_path, sep=\"\\t\", skiprows=data_start_idx)\n\n    # Combine Date and Time columns\n    df[\"Timestamp\"] = pd.to_datetime(\n        df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str)\n    )\n    df = df.drop([\"Date\", \"Time\"], axis=1)\n\n    # Add metadata as attributes\n    df.attrs.update(metadata.items())  # ignore\n\n    return df\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_metadata_section","title":"parse_metadata_section","text":"<pre><code>parse_metadata_section(lines: list) -&gt; dict[str, Any]\n</code></pre> <p>Parse the metadata section at the top of log files.</p> <p>Parameters:</p> <ul> <li> <code>lines</code>               (<code>list</code>)           \u2013            <p>List of lines from the file</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>           \u2013            <p>Dictionary containing metadata</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_metadata_section(lines: list) -&gt; dict[str, Any]:\n    \"\"\"\n    Parse the metadata section at the top of log files.\n\n    Args:\n        lines: List of lines from the file\n\n    Returns:\n        Dictionary containing metadata\n    \"\"\"\n    metadata = {}\n\n    for line in lines:\n        if \":\" in line and not line.startswith(\"Date/Time\"):\n            # Handle metadata lines like \"Name: user\" or \"Date: 1/17/2023\"\n            key, value = line.split(\":\", 1)\n            metadata[key.strip()] = value.strip()\n        elif line.strip() and not any(char.isdigit() for char in line.split(\"\\t\")[0]):\n            # Stop at data lines (which start with dates/times)\n            continue\n        else:\n            break\n\n    return metadata\n</code></pre>"},{"location":"reference/chromstream/parsers.html#chromstream.parsers.parse_to_channel","title":"parse_to_channel","text":"<pre><code>parse_to_channel(files: list[str | Path] | str | Path, channel_name: Optional[str] = None) -&gt; ChannelChromatograms\n</code></pre> <p>Parses multiple chromatogram txt files into a ChannelChromatograms object. Takes either a directory path or a list of file paths. The chromatograms are loaded, sorted by the injection time, assigned a number, and added to the ChannelChromatograms object.</p> <p>Parameters:</p> <ul> <li> <code>files</code>               (<code>list[str | Path] | str | Path</code>)           \u2013            <p>List of file paths or a directory path containing chromatogram files.</p> </li> <li> <code>Channel</code>               (<code>Optional[str]</code>)           \u2013            <p>Optional channel name to override the one in the metadata.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ChannelChromatograms</code> (              <code>ChannelChromatograms</code> )          \u2013            <p>Parsed ChannelChromatograms object containing all chromatograms.</p> </li> </ul> Source code in <code>chromstream/parsers.py</code> <pre><code>def parse_to_channel(\n    files: list[str | Path] | str | Path, channel_name: Optional[str] = None\n) -&gt; ChannelChromatograms:\n    \"\"\"\n    Parses multiple chromatogram txt files into a ChannelChromatograms object.\n    Takes either a directory path or a list of file paths.\n    The chromatograms are loaded, sorted by the injection time, assigned a number, and added to the ChannelChromatograms object.\n\n    Args:\n        files (list[str | Path] | str | Path): List of file paths or a directory path containing chromatogram files.\n        Channel (Optional[str]): Optional channel name to override the one in the metadata.\n\n    Returns:\n        ChannelChromatograms: Parsed ChannelChromatograms object containing all chromatograms.\n    \"\"\"\n    if isinstance(files, (str, Path)):\n        files = sorted(Path(files).iterdir())\n\n    chromatograms = []\n    channel = None\n    for file in files:\n        try:\n            chrom = parse_chromatogram_txt(file)\n            chromatograms.append(chrom)\n            if channel is None:\n                channel = chrom.channel\n            elif channel != chrom.channel:\n                log.critical(\n                    f\"Channel mismatch: {channel} vs {chrom.channel} in file {file}\"\n                )\n        except Exception as e:\n            log.warning(f\"Failed to parse {file}: {e}\")\n\n    # Sort chromatograms by injection time\n    chromatograms.sort(key=lambda x: x.injection_time)\n\n    if not chromatograms:\n        raise ValueError(\"No valid chromatograms were parsed.\")\n    # use the manual channel name, if not provided, use the one from the first chromatogram\n    channel = channel_name if channel_name else chromatograms[0].channel\n\n    # initialize ChannelChromatograms object\n    channel_chroms = ChannelChromatograms(channel=channel)\n\n    # adding chromatograms with injection number\n    for i, chrom in enumerate(chromatograms, start=0):\n        channel_chroms.add_chromatogram(i, chrom)\n\n    return channel_chroms\n</code></pre>"},{"location":"resources/examples.html","title":"Example Notebooks","text":"<p>This section contains example notebooks for the ChromStream package.  Running of these notebooks requires development data which will be uploaded to a seperate repository.</p>"},{"location":"resources/examples.html#available-examples","title":"Available Examples","text":""},{"location":"resources/examples.html#quickstart-guide","title":"Quickstart Guide","text":"<p>Provides an introduction to ChromStream's core functionality. This notebook covers: - Setting up experiments - Loading chromatographic data - Basic plotting and visualization - Working with channels and chromatograms</p>"},{"location":"resources/examples.html#calibration-example","title":"Calibration Example","text":"<p>Shows how to calibrate two GC systems: - A conventional on-line GC - A specilized system with heated sample loops</p>"},{"location":"resources/examples.html#cracking-example","title":"Cracking Example","text":"<p>Provides an example analysis for cracking of a light hydrocarbon - Importing, baseline correction and integration - Applying of an internal standard - Estimation of partial pressures using a calibration - Adding data from log files (e.g. Temperature) to the analysis</p>"}]}